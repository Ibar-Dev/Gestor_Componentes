{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibar-Dev/Gestor_Componentes/blob/main/Necesito_que_me_ayudes_a_organizar_el_c%C3%B3digo_que_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Claro que sí! Organizar el código en clases bien definidas y un script principal es una excelente práctica para mejorar la mantenibilidad y la claridad de tu proyecto. 👍\n",
        "\n",
        "Aquí te presento la estructura que propongo y el código para cada archivo:\n",
        "\n",
        "**Estructura de Archivos Sugerida:**\n",
        "\n",
        "1.  `config.py`: Para constantes y configuraciones (como `CONFIG_FILE` y `MAPEO_MAGNITUDES_PREDEFINIDO`).\n",
        "2.  `enums.py`: Para la enumeración `OrigenResultados`.\n",
        "3.  `utilidades.py`: Para las clases `ExtractorMagnitud` y `ManejadorExcel`.\n",
        "4.  `motor_busqueda.py`: Para la clase `MotorBusqueda`.\n",
        "5.  `interfaz_grafica.py`: Para la clase `InterfazGrafica`.\n",
        "6.  `main.py`: El script principal que une todo.\n",
        "\n",
        "---\n",
        "## 1. `config.py`"
      ],
      "metadata": {
        "id": "LylFTMRQc7x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "from typing import Dict, List\n",
        "\n",
        "CONFIG_FILE_NAME = \"config_buscador_v0_7_1_mapeo.json\"\n",
        "LOG_FILE_NAME = \"buscador_app_v0_7_1_mapeo.log\"\n",
        "\n",
        "# Mapeo de magnitudes predefinido, movido aquí para centralizar configuración.\n",
        "MAPEO_MAGNITUDES_PREDEFINIDO: Dict[str, List[str]] = {\n",
        "    \"AMPERIOS\": [\"A\", \"AMP\", \"AMPS\"],\n",
        "    \"VOLTIOS\": [\"V\", \"VA\", \"VAC\", \"VC\", \"VCC\", \"VCD\", \"VDC\"],\n",
        "    \"VATIOS\": [\"W\", \"WATTS\"],\n",
        "    \"GIGABIT\": [\"G\", \"GB\", \"GBE\", \"GE\", \"GBIT\"],\n",
        "    \"PUERTO\": [\"P\", \"PORT\", \"PORTS\", \"PTOS\"],\n",
        "    \"HERTZ\": [\"HZ\", \"KHZ\", \"MHZ\", \"GHZ\"],\n",
        "    \"AH\": [], \"ANTENNA\": [], \"BASE\": [], \"BIT\": [], \"ETH\": [], \"FE\": [],\n",
        "    \"GBASE\": [], \"GBASEWAN\": [], \"GBIC\": [], \"GBPS\": [], \"GH\": [], \"KM\": [],\n",
        "    \"KVA\": [], \"KW\": [], \"LINEAS\": [], \"LINES\": [], \"NM\": [], \"E\": [],\n",
        "    \"POTS\": [], \"STM\": []\n",
        "}\n",
        "\n",
        "# Otros valores de configuración que puedan ser necesarios\n",
        "# Ejemplo:\n",
        "# DEFAULT_WINDOW_GEOMETRY = \"1250x800\"\n",
        "# DEFAULT_LOG_LEVEL = \"INFO\" # o logging.INFO si se importa logging aquí"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "_qjPvDxec7x_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. `enums.py`"
      ],
      "metadata": {
        "id": "VYSJdc65c7yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enums.py\n",
        "from enum import Enum, auto\n",
        "\n",
        "class OrigenResultados(Enum):\n",
        "    NINGUNO = 0\n",
        "    VIA_DICCIONARIO_CON_RESULTADOS_DESC = auto()\n",
        "    VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS = auto()\n",
        "    VIA_DICCIONARIO_SIN_RESULTADOS_DESC = auto()\n",
        "    DIRECTO_DESCRIPCION_CON_RESULTADOS = auto()\n",
        "    DIRECTO_DESCRIPCION_VACIA = auto()\n",
        "    ERROR_CARGA_DICCIONARIO = auto()\n",
        "    ERROR_CARGA_DESCRIPCION = auto()\n",
        "    ERROR_CONFIGURACION_COLUMNAS_DICC = auto()\n",
        "    ERROR_CONFIGURACION_COLUMNAS_DESC = auto()\n",
        "    ERROR_BUSQUEDA_INTERNA_MOTOR = auto()\n",
        "    TERMINO_INVALIDO = auto()\n",
        "\n",
        "    @property\n",
        "    def es_via_diccionario(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC,\n",
        "            OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS,\n",
        "            OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_directo_descripcion(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.DIRECTO_DESCRIPCION_CON_RESULTADOS,\n",
        "            OrigenResultados.DIRECTO_DESCRIPCION_VACIA,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_error_carga(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.ERROR_CARGA_DICCIONARIO,\n",
        "            OrigenResultados.ERROR_CARGA_DESCRIPCION,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_error_configuracion(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DICC,\n",
        "            OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DESC,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_error_operacional(self) -> bool:\n",
        "        return self == OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR\n",
        "\n",
        "    @property\n",
        "    def es_termino_invalido(self) -> bool:\n",
        "        return self == OrigenResultados.TERMINO_INVALIDO"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "n5gB1u2jc7yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. `utilidades.py`"
      ],
      "metadata": {
        "id": "gAjXc9Eoc7yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utilidades.py\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "\n",
        "# Importar configuración\n",
        "from config import MAPEO_MAGNITUDES_PREDEFINIDO\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ExtractorMagnitud:\n",
        "    def __init__(self, mapeo_magnitudes: Optional[Dict[str, List[str]]] = None):\n",
        "        self.sinonimo_a_canonico_normalizado: Dict[str, str] = {}\n",
        "        # Usar el mapeo de config.py si no se proporciona uno específico\n",
        "        mapeo_a_usar = mapeo_magnitudes if mapeo_magnitudes is not None else MAPEO_MAGNITUDES_PREDEFINIDO\n",
        "\n",
        "        for forma_canonica, lista_sinonimos in mapeo_a_usar.items():\n",
        "            canonico_norm = self._normalizar_texto(forma_canonica)\n",
        "            if not canonico_norm:\n",
        "                logger.warning(f\"Forma canónica '{forma_canonica}' resultó vacía tras normalizar. Se ignora.\")\n",
        "                continue\n",
        "\n",
        "            self.sinonimo_a_canonico_normalizado[canonico_norm] = canonico_norm\n",
        "\n",
        "            for sinonimo in lista_sinonimos:\n",
        "                sinonimo_norm = self._normalizar_texto(sinonimo)\n",
        "                if sinonimo_norm:\n",
        "                    if sinonimo_norm in self.sinonimo_a_canonico_normalizado and \\\n",
        "                       self.sinonimo_a_canonico_normalizado[sinonimo_norm] != canonico_norm:\n",
        "                        logger.warning(\n",
        "                            f\"Conflicto de mapeo: El sinónimo normalizado '{sinonimo_norm}' (de '{sinonimo}' para '{forma_canonica}') \"\n",
        "                            f\"ya está mapeado a '{self.sinonimo_a_canonico_normalizado[sinonimo_norm]}'. \"\n",
        "                            f\"Se sobrescribirá con el mapeo a '{canonico_norm}'. \"\n",
        "                            \"Revise su MAPEO_MAGNITUDES_PREDEFINIDO para evitar ambigüedades.\"\n",
        "                        )\n",
        "                    self.sinonimo_a_canonico_normalizado[sinonimo_norm] = canonico_norm\n",
        "        logger.debug(f\"ExtractorMagnitud inicializado con mapeo: {self.sinonimo_a_canonico_normalizado}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalizar_texto(texto: str) -> str:\n",
        "        if not isinstance(texto, str) or not texto:\n",
        "            return \"\"\n",
        "        try:\n",
        "            texto_upper = texto.upper()\n",
        "            forma_normalizada = unicodedata.normalize(\"NFKD\", texto_upper)\n",
        "            return \"\".join(c for c in forma_normalizada if not unicodedata.combining(c))\n",
        "        except TypeError:\n",
        "            return \"\"\n",
        "\n",
        "    def obtener_magnitud_normalizada(self, texto_unidad: str) -> Optional[str]:\n",
        "        if not texto_unidad:\n",
        "            return None\n",
        "        normalizada = self._normalizar_texto(texto_unidad)\n",
        "        if not normalizada:\n",
        "            return None\n",
        "        return self.sinonimo_a_canonico_normalizado.get(normalizada)\n",
        "\n",
        "\n",
        "class ManejadorExcel:\n",
        "    @staticmethod\n",
        "    def cargar_excel(\n",
        "        ruta_archivo: Union[str, Path],\n",
        "    ) -> Tuple[Optional[pd.DataFrame], Optional[str]]:\n",
        "        ruta = Path(ruta_archivo)\n",
        "        logger.info(f\"Intentando cargar archivo Excel: {ruta}\")\n",
        "        if not ruta.exists():\n",
        "            error_msg = f\"¡Archivo no encontrado! Ruta: {ruta}\"\n",
        "            logger.error(error_msg)\n",
        "            return None, error_msg\n",
        "        try:\n",
        "            engine = \"openpyxl\" if ruta.suffix.lower() == \".xlsx\" else None\n",
        "            df = pd.read_excel(ruta, engine=engine)\n",
        "            logger.info(f\"Archivo '{ruta.name}' cargado ({len(df)} filas).\")\n",
        "            return df, None\n",
        "        except Exception as e:\n",
        "            error_msg = (\n",
        "                f\"No se pudo cargar el archivo:\\n{ruta}\\n\\nError: {e}\\n\\n\"\n",
        "                \"Posibles causas:\\n\"\n",
        "                \"- El archivo está siendo usado por otro programa.\\n\"\n",
        "                \"- No tiene instalado 'openpyxl' para .xlsx (o 'xlrd' para .xls).\\n\"\n",
        "                \"- El archivo está corrupto o en formato no soportado.\"\n",
        "            )\n",
        "            logger.exception(f\"Error inesperado al cargar archivo Excel: {ruta}\")\n",
        "            return None, error_msg"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "huNo7B91c7yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. `motor_busqueda.py`"
      ],
      "metadata": {
        "id": "rpCrW7m4c7yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# motor_busqueda.py\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Optional, List, Tuple, Dict, Any, Set, Union\n",
        "\n",
        "from enums import OrigenResultados\n",
        "from utilidades import ExtractorMagnitud, ManejadorExcel\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class MotorBusqueda:\n",
        "    def __init__(self, indices_diccionario_cfg: Optional[List[int]] = None):\n",
        "        self.datos_diccionario: Optional[pd.DataFrame] = None\n",
        "        self.datos_descripcion: Optional[pd.DataFrame] = None\n",
        "        self.archivo_diccionario_actual: Optional[Path] = None\n",
        "        self.archivo_descripcion_actual: Optional[Path] = None\n",
        "\n",
        "        self.indices_columnas_busqueda_dic: List[int] = (\n",
        "            indices_diccionario_cfg if isinstance(indices_diccionario_cfg, list) else []\n",
        "        )\n",
        "        logger.info(\n",
        "            f\"MotorBusqueda inicializado. Índices búsqueda diccionario: {self.indices_columnas_busqueda_dic or 'Todas las de texto'}\"\n",
        "        )\n",
        "\n",
        "        self.patron_comparacion = re.compile(\n",
        "            r\"^([<>]=?)(\\d+(?:[.,]\\d+)?)\\s*([a-zA-ZáéíóúÁÉÍÓÚñÑµΩ]+)?(.*)$\"\n",
        "        )\n",
        "        self.patron_rango = re.compile(\n",
        "            r\"^(\\d+(?:[.,]\\d+)?)\\s*-\\s*(\\d+(?:[.,]\\d+)?)\\s*([a-zA-ZáéíóúÁÉÍÓÚñÑµΩ]+)?$\"\n",
        "        )\n",
        "        self.patron_negacion = re.compile(r\"^#(.+)$\")\n",
        "        self.patron_num_unidad_df = re.compile(\n",
        "            r\"(\\d+(?:[.,]\\d+)?)\\s*([a-zA-ZáéíóúÁÉÍÓÚñÑµΩ]+)?\"\n",
        "        )\n",
        "        self.extractor_magnitud = ExtractorMagnitud() # Usa el mapeo por defecto de config.py\n",
        "\n",
        "    def cargar_excel_diccionario(self, ruta_str: str) -> Tuple[bool, Optional[str]]:\n",
        "        ruta = Path(ruta_str)\n",
        "        df_cargado, error_msg_carga = ManejadorExcel.cargar_excel(ruta)\n",
        "\n",
        "        if df_cargado is None:\n",
        "            self.datos_diccionario = None\n",
        "            self.archivo_diccionario_actual = None\n",
        "            return False, error_msg_carga or \"Error desconocido al cargar diccionario.\"\n",
        "\n",
        "        valido, msg_val_cols = self._validar_columnas_df(\n",
        "            df_cargado, self.indices_columnas_busqueda_dic, \"diccionario\"\n",
        "        )\n",
        "        if not valido:\n",
        "            logger.warning(\n",
        "                f\"Validación de columnas del diccionario fallida. Carga invalidada. Causa: {msg_val_cols}\"\n",
        "            )\n",
        "            return False, msg_val_cols or \"Validación de columnas del diccionario fallida.\"\n",
        "\n",
        "        self.datos_diccionario = df_cargado\n",
        "        self.archivo_diccionario_actual = ruta\n",
        "        return True, None\n",
        "\n",
        "    def cargar_excel_descripcion(self, ruta_str: str) -> Tuple[bool, Optional[str]]:\n",
        "        ruta = Path(ruta_str)\n",
        "        df_cargado, error_msg_carga = ManejadorExcel.cargar_excel(ruta)\n",
        "\n",
        "        if df_cargado is None:\n",
        "            self.datos_descripcion = None\n",
        "            self.archivo_descripcion_actual = None\n",
        "            return False, error_msg_carga or \"Error desconocido al cargar descripciones.\"\n",
        "\n",
        "        self.datos_descripcion = df_cargado\n",
        "        self.archivo_descripcion_actual = ruta\n",
        "        return True, None\n",
        "\n",
        "    def _validar_columnas_df(\n",
        "        self, df: Optional[pd.DataFrame], indices_cfg: List[int], nombre_df_log: str\n",
        "    ) -> Tuple[bool, Optional[str]]:\n",
        "        if df is None:\n",
        "            msg = f\"DataFrame '{nombre_df_log}' es None, no se puede validar.\"\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "\n",
        "        num_cols_df = len(df.columns)\n",
        "\n",
        "        if not indices_cfg or indices_cfg == [-1]:\n",
        "            if num_cols_df == 0:\n",
        "                msg = f\"El archivo del {nombre_df_log} está vacío o no contiene columnas (modo 'todas').\"\n",
        "                logger.error(msg)\n",
        "                return False, msg\n",
        "            return True, None\n",
        "\n",
        "        if not all(isinstance(idx, int) and idx >= 0 for idx in indices_cfg):\n",
        "            msg = f\"Configuración de índices para {nombre_df_log} inválida: {indices_cfg}. Deben ser enteros no negativos.\"\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "\n",
        "        max_indice_requerido = max(indices_cfg) if indices_cfg else -1\n",
        "\n",
        "        if num_cols_df == 0:\n",
        "            msg = f\"El {nombre_df_log} no tiene columnas.\"\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "        elif max_indice_requerido >= num_cols_df:\n",
        "            msg = (\n",
        "                f\"El {nombre_df_log} necesita al menos {max_indice_requerido + 1} columnas \"\n",
        "                f\"para los índices configurados ({indices_cfg}), pero solo tiene {num_cols_df}.\"\n",
        "            )\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "        return True, None\n",
        "\n",
        "    def _obtener_nombres_columnas_busqueda_df(\n",
        "        self, df: Optional[pd.DataFrame], indices_cfg: List[int], nombre_df_log: str\n",
        "    ) -> Tuple[Optional[List[str]], Optional[str]]:\n",
        "        if df is None:\n",
        "            msg = f\"Intentando obtener nombres de columnas de un DataFrame ({nombre_df_log}) que es None.\"\n",
        "            logger.error(msg)\n",
        "            return None, msg\n",
        "\n",
        "        columnas_disponibles = df.columns\n",
        "        num_cols_df = len(columnas_disponibles)\n",
        "\n",
        "        if not indices_cfg or indices_cfg == [-1]:\n",
        "            cols_texto_obj = [\n",
        "                col for col in df.columns\n",
        "                if pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col])\n",
        "            ]\n",
        "            if cols_texto_obj:\n",
        "                logger.info(\n",
        "                    f\"Buscando en columnas de texto/object (detectadas) del {nombre_df_log}: {cols_texto_obj}\"\n",
        "                )\n",
        "                return cols_texto_obj, None\n",
        "            elif num_cols_df > 0:\n",
        "                logger.warning(\n",
        "                    f\"No se encontraron columnas de texto/object en {nombre_df_log}. Se usarán todas las {num_cols_df} columnas.\"\n",
        "                )\n",
        "                return list(df.columns), None\n",
        "            else:\n",
        "                msg = f\"El DataFrame del {nombre_df_log} no tiene columnas.\"\n",
        "                logger.error(msg)\n",
        "                return None, msg\n",
        "\n",
        "        nombres_columnas_seleccionadas = []\n",
        "        indices_validos_usados = []\n",
        "        for indice in indices_cfg:\n",
        "            if 0 <= indice < num_cols_df:\n",
        "                nombres_columnas_seleccionadas.append(columnas_disponibles[indice])\n",
        "                indices_validos_usados.append(indice)\n",
        "            else:\n",
        "                logger.warning(\n",
        "                    f\"Índice {indice} para {nombre_df_log} es inválido o fuera de rango (0 a {num_cols_df-1}). Ignorado.\"\n",
        "                )\n",
        "\n",
        "        if not nombres_columnas_seleccionadas:\n",
        "            msg = f\"No se encontraron columnas válidas en {nombre_df_log} con los índices configurados: {indices_cfg}\"\n",
        "            logger.error(msg)\n",
        "            return None, msg\n",
        "\n",
        "        logger.debug(\n",
        "            f\"Se buscará en columnas del {nombre_df_log}: {nombres_columnas_seleccionadas} (índices: {indices_validos_usados})\"\n",
        "        )\n",
        "        return nombres_columnas_seleccionadas, None\n",
        "\n",
        "    def _parsear_nivel1_or(self, texto_complejo: str) -> Tuple[str, List[str]]:\n",
        "        texto_limpio = texto_complejo.strip()\n",
        "        if not texto_limpio:\n",
        "            return 'OR', []\n",
        "\n",
        "        if '|' in texto_limpio:\n",
        "            segmentos = [s.strip() for s in re.split(r'\\s*\\|\\s*', texto_limpio) if s.strip()]\n",
        "            return 'OR', segmentos\n",
        "        elif '/' in texto_limpio:\n",
        "            segmentos = [s.strip() for s in re.split(r'\\s*/\\s*', texto_limpio) if s.strip()]\n",
        "            return 'OR', segmentos\n",
        "        else:\n",
        "            return 'AND', [texto_limpio]\n",
        "\n",
        "    def _parsear_nivel2_and(self, termino_segmento_n1: str) -> Tuple[str, List[str]]:\n",
        "        termino_limpio = termino_segmento_n1.strip()\n",
        "        if not termino_limpio:\n",
        "            return 'AND', []\n",
        "\n",
        "        op_principal_interno = 'AND'\n",
        "        separador_interno = None\n",
        "\n",
        "        if '+' in termino_limpio:\n",
        "            separador_interno = '+'\n",
        "\n",
        "        terminos_brutos_finales = []\n",
        "        if separador_interno:\n",
        "            estado = 0\n",
        "            termino_actual_maquina = []\n",
        "            pos = 0\n",
        "            while pos < len(termino_limpio):\n",
        "                char = termino_limpio[pos]\n",
        "                if estado == 0:\n",
        "                    if char == separador_interno:\n",
        "                        sub_termino = \"\".join(termino_actual_maquina).strip()\n",
        "                        if sub_termino: terminos_brutos_finales.append(sub_termino)\n",
        "                        termino_actual_maquina = []\n",
        "                    elif char in \"<>=\":\n",
        "                        estado = 1\n",
        "                        termino_actual_maquina.append(char)\n",
        "                    elif char.isdigit():\n",
        "                        estado = 2\n",
        "                        termino_actual_maquina.append(char)\n",
        "                    else:\n",
        "                        termino_actual_maquina.append(char)\n",
        "                elif estado == 1:\n",
        "                    termino_actual_maquina.append(char)\n",
        "                    if char.isdigit() or char == \".\":\n",
        "                        estado = 2\n",
        "                    elif char.isspace() and not any(c in \"<>=\" for c in termino_actual_maquina[-2:]):\n",
        "                        if \"\".join(termino_actual_maquina).strip() in ['<','>','<=','>=','=']:\n",
        "                           pass\n",
        "                        else:\n",
        "                           estado = 0\n",
        "                    elif not (char in \"<>=\" or char.isalnum() or char in ['.',',','-']):\n",
        "                        estado = 0\n",
        "                elif estado == 2:\n",
        "                    termino_actual_maquina.append(char)\n",
        "                    if not (char.isdigit() or char in ['.', ',']):\n",
        "                        if char.isalpha():\n",
        "                            estado = 3\n",
        "                        else:\n",
        "                            estado = 0\n",
        "                elif estado == 3:\n",
        "                    termino_actual_maquina.append(char)\n",
        "                    if not char.isalnum():\n",
        "                        estado = 0\n",
        "                pos += 1\n",
        "\n",
        "            sub_termino_final = \"\".join(termino_actual_maquina).strip()\n",
        "            if sub_termino_final: terminos_brutos_finales.append(sub_termino_final)\n",
        "\n",
        "            if not terminos_brutos_finales and termino_limpio == separador_interno:\n",
        "                return op_principal_interno, []\n",
        "        else:\n",
        "            terminos_brutos_finales = [termino_limpio]\n",
        "\n",
        "        return op_principal_interno, [t for t in terminos_brutos_finales if t]\n",
        "\n",
        "    def _analizar_terminos(self, terminos_brutos: List[str]) -> List[Dict[str, Any]]:\n",
        "        palabras_analizadas = []\n",
        "        for term_orig_bruto in terminos_brutos:\n",
        "            term_orig = str(term_orig_bruto)\n",
        "            term = term_orig.strip()\n",
        "            if not term: continue\n",
        "\n",
        "            item_analizado: Dict[str, Any] = {'original': term_orig, 'negate': False}\n",
        "            match_neg = self.patron_negacion.match(term)\n",
        "            if match_neg:\n",
        "                item_analizado['negate'] = True\n",
        "                term = match_neg.group(1).strip()\n",
        "                if not term: continue\n",
        "\n",
        "            match_comp = self.patron_comparacion.match(term)\n",
        "            match_range = self.patron_rango.match(term)\n",
        "\n",
        "            if match_comp:\n",
        "                op, v_str, unidad_str, _ = match_comp.groups()\n",
        "                v_num = self._parse_numero(v_str)\n",
        "                if v_num is not None:\n",
        "                    op_map = {'>': 'gt', '<': 'lt', '>=': 'ge', '<=': 'le', '=': 'eq'}\n",
        "                    unidad_canon_comp = None\n",
        "                    if unidad_str:\n",
        "                        unidad_canon_comp = self.extractor_magnitud.obtener_magnitud_normalizada(unidad_str.strip())\n",
        "                        if unidad_canon_comp is None:\n",
        "                            logger.warning(\n",
        "                                f\"Unidad de búsqueda '{unidad_str.strip()}' en '{term}' no reconocida. \"\n",
        "                                \"Comparación numérica sin filtro de unidad.\"\n",
        "                            )\n",
        "                    item_analizado.update({\n",
        "                        'tipo': op_map.get(op, 'str'),\n",
        "                        'valor': v_num,\n",
        "                        'unidad_busqueda': unidad_canon_comp\n",
        "                    })\n",
        "                else:\n",
        "                    item_analizado.update({'tipo': 'str', 'valor': self.extractor_magnitud._normalizar_texto(term)})\n",
        "            elif match_range:\n",
        "                v1_str, v2_str, unidad_rango_str = match_range.groups()\n",
        "                v1, v2 = self._parse_numero(v1_str), self._parse_numero(v2_str)\n",
        "                if v1 is not None and v2 is not None:\n",
        "                    unidad_canon_range = None\n",
        "                    if unidad_rango_str:\n",
        "                        unidad_canon_range = self.extractor_magnitud.obtener_magnitud_normalizada(unidad_rango_str.strip())\n",
        "                        if unidad_canon_range is None:\n",
        "                            logger.warning(\n",
        "                                f\"Unidad de rango '{unidad_rango_str.strip()}' en '{term}' no reconocida. \"\n",
        "                                \"Rango sin filtro de unidad.\"\n",
        "                            )\n",
        "                    item_analizado.update({\n",
        "                        'tipo': 'range',\n",
        "                        'valor': sorted([v1, v2]),\n",
        "                        'unidad_busqueda': unidad_canon_range\n",
        "                    })\n",
        "                else:\n",
        "                    item_analizado.update({'tipo': 'str', 'valor': self.extractor_magnitud._normalizar_texto(term)})\n",
        "            else:\n",
        "                item_analizado.update({'tipo': 'str', 'valor': self.extractor_magnitud._normalizar_texto(term)})\n",
        "            palabras_analizadas.append(item_analizado)\n",
        "        logger.debug(f\"Términos analizados (motor): {palabras_analizadas}\")\n",
        "        return palabras_analizadas\n",
        "\n",
        "    def _parse_numero(self, num_str: Any) -> Optional[float]:\n",
        "        if not isinstance(num_str, (str, int, float)): return None\n",
        "        try:\n",
        "            return float(str(num_str).replace(',', '.'))\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "    def _generar_mascara_para_un_termino(self, df: pd.DataFrame, cols_a_buscar: List[str], termino_analizado: Dict[str, Any]) -> pd.Series:\n",
        "        mascara_total_subtermino = pd.Series(False, index=df.index)\n",
        "        tipo_sub = termino_analizado['tipo']\n",
        "        valor_sub = termino_analizado['valor']\n",
        "        unidad_sub_requerida_canon = termino_analizado.get('unidad_busqueda')\n",
        "        es_negado = termino_analizado.get('negate', False)\n",
        "\n",
        "        for col_nombre in cols_a_buscar:\n",
        "            if col_nombre not in df.columns:\n",
        "                logger.warning(f\"Columna '{col_nombre}' no encontrada en DF. Saltando.\")\n",
        "                continue\n",
        "            col_series = df[col_nombre]\n",
        "            mascara_col_actual = pd.Series(False, index=df.index)\n",
        "\n",
        "            if tipo_sub in ['gt', 'lt', 'ge', 'le', 'range', 'eq']:\n",
        "                for idx, valor_celda in col_series.items():\n",
        "                    if pd.isna(valor_celda) or str(valor_celda).strip() == \"\": continue\n",
        "\n",
        "                    for match_celda in self.patron_num_unidad_df.finditer(str(valor_celda)):\n",
        "                        try:\n",
        "                            num_celda_val = float(match_celda.group(1).replace(',', '.'))\n",
        "                            unidad_celda_canon: Optional[str] = None\n",
        "                            if match_celda.group(2):\n",
        "                                unidad_celda_canon = self.extractor_magnitud.obtener_magnitud_normalizada(match_celda.group(2))\n",
        "\n",
        "                            unidad_coincide = False\n",
        "                            if unidad_sub_requerida_canon is None:\n",
        "                                unidad_coincide = True\n",
        "                            elif unidad_celda_canon is not None and unidad_celda_canon == unidad_sub_requerida_canon:\n",
        "                                unidad_coincide = True\n",
        "\n",
        "                            if not unidad_coincide:\n",
        "                                continue\n",
        "\n",
        "                            cond_ok = False\n",
        "                            if tipo_sub == 'eq' and num_celda_val == valor_sub : cond_ok = True\n",
        "                            elif tipo_sub == 'gt' and num_celda_val > valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'lt' and num_celda_val < valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'ge' and num_celda_val >= valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'le' and num_celda_val <= valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'range' and valor_sub[0] <= num_celda_val <= valor_sub[1]: cond_ok = True\n",
        "\n",
        "                            if cond_ok:\n",
        "                                mascara_col_actual.at[idx] = True\n",
        "                                break\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "                    if mascara_col_actual.at[idx]: continue\n",
        "\n",
        "            elif tipo_sub == 'str':\n",
        "                termino_regex_escapado = r\"\\b\" + re.escape(str(valor_sub)) + r\"\\b\"\n",
        "                try:\n",
        "                    serie_normalizada = col_series.astype(str).map(self.extractor_magnitud._normalizar_texto)\n",
        "                    mascara_col_actual = serie_normalizada.str.contains(termino_regex_escapado, regex=True, na=False)\n",
        "                except Exception as e_conv_str:\n",
        "                    logger.warning(f\"No se pudo convertir/buscar string en columna '{col_nombre}': {e_conv_str}\")\n",
        "\n",
        "            mascara_total_subtermino |= mascara_col_actual.fillna(False)\n",
        "\n",
        "        return ~mascara_total_subtermino if es_negado else mascara_total_subtermino\n",
        "\n",
        "    def _aplicar_mascara_combinada_para_segmento_and(\n",
        "        self, df: pd.DataFrame, cols_a_buscar: List[str], terminos_analizados_segmento: List[Dict[str, Any]]\n",
        "    ) -> pd.Series:\n",
        "        if df is None or df.empty or not cols_a_buscar:\n",
        "            return pd.Series(False, index=df.index if df is not None else None)\n",
        "\n",
        "        if not terminos_analizados_segmento:\n",
        "            return pd.Series(False, index=df.index)\n",
        "\n",
        "        mascara_final_segmento_and = pd.Series(True, index=df.index)\n",
        "\n",
        "        for termino_individual_analizado in terminos_analizados_segmento:\n",
        "            mascara_este_termino = self._generar_mascara_para_un_termino(df, cols_a_buscar, termino_individual_analizado)\n",
        "            mascara_final_segmento_and &= mascara_este_termino\n",
        "\n",
        "        return mascara_final_segmento_and\n",
        "\n",
        "    def _combinar_mascaras_de_segmentos_or(self, lista_mascaras_segmentos: List[pd.Series], df_index_ref: pd.Index) -> pd.Series:\n",
        "        if not lista_mascaras_segmentos:\n",
        "            return pd.Series(False, index=df_index_ref)\n",
        "\n",
        "        mascara_final_or = pd.Series(False, index=lista_mascaras_segmentos[0].index)\n",
        "        for mascara_segmento in lista_mascaras_segmentos:\n",
        "            mascara_final_or |= mascara_segmento\n",
        "        return mascara_final_or\n",
        "\n",
        "    def _procesar_busqueda_en_df_objetivo(\n",
        "        self,\n",
        "        df_objetivo: pd.DataFrame,\n",
        "        cols_objetivo: List[str],\n",
        "        termino_busqueda_original: str\n",
        "    ) -> Tuple[pd.DataFrame, Optional[str]]:\n",
        "\n",
        "        if not termino_busqueda_original.strip():\n",
        "            return df_objetivo.copy(), None\n",
        "\n",
        "        op_nivel1, segmentos_nivel1 = self._parsear_nivel1_or(termino_busqueda_original)\n",
        "\n",
        "        if not segmentos_nivel1:\n",
        "            return pd.DataFrame(columns=df_objetivo.columns), \"Término de búsqueda inválido o vacío tras parseo OR.\"\n",
        "\n",
        "        lista_mascaras_para_or = []\n",
        "        for seg_n1 in segmentos_nivel1:\n",
        "            op_nivel2, terminos_brutos_n2 = self._parsear_nivel2_and(seg_n1)\n",
        "\n",
        "            terminos_atomicos_analizados = self._analizar_terminos(terminos_brutos_n2)\n",
        "\n",
        "            if not terminos_atomicos_analizados:\n",
        "                logger.warning(f\"Segmento OR '{seg_n1}' no produjo términos analizables. No contribuirá.\")\n",
        "                mascara_segmento_n1 = pd.Series(False, index=df_objetivo.index)\n",
        "            else:\n",
        "                mascara_segmento_n1 = self._aplicar_mascara_combinada_para_segmento_and(\n",
        "                    df_objetivo, cols_objetivo, terminos_atomicos_analizados\n",
        "                )\n",
        "            lista_mascaras_para_or.append(mascara_segmento_n1)\n",
        "\n",
        "        if not lista_mascaras_para_or:\n",
        "             return pd.DataFrame(columns=df_objetivo.columns), \"Ningún segmento de búsqueda produjo resultados.\"\n",
        "\n",
        "        mascara_final_df_objetivo = self._combinar_mascaras_de_segmentos_or(lista_mascaras_para_or, df_objetivo.index)\n",
        "        return df_objetivo[mascara_final_df_objetivo].copy(), None\n",
        "\n",
        "    def buscar(\n",
        "        self,\n",
        "        termino_busqueda_original: str,\n",
        "        buscar_via_diccionario_flag: bool,\n",
        "    ) -> Tuple[Optional[pd.DataFrame], OrigenResultados, Optional[pd.DataFrame], Optional[str]]:\n",
        "        logger.info(\n",
        "            f\"Motor.buscar: termino='{termino_busqueda_original}', via_dicc={buscar_via_diccionario_flag}\"\n",
        "        )\n",
        "\n",
        "        fcds_obtenidos: Optional[pd.DataFrame] = None\n",
        "        df_vacio_desc = pd.DataFrame(columns=self.datos_descripcion.columns if self.datos_descripcion is not None else [])\n",
        "\n",
        "        if not termino_busqueda_original.strip():\n",
        "            if self.datos_descripcion is not None:\n",
        "                return self.datos_descripcion.copy(), OrigenResultados.DIRECTO_DESCRIPCION_VACIA, None, None\n",
        "            return df_vacio_desc, OrigenResultados.ERROR_CARGA_DESCRIPCION, None, \"Descripciones no cargadas.\"\n",
        "\n",
        "        if buscar_via_diccionario_flag:\n",
        "            if self.datos_diccionario is None:\n",
        "                return None, OrigenResultados.ERROR_CARGA_DICCIONARIO, None, \"Diccionario no cargado.\"\n",
        "\n",
        "            cols_dic, err_cols_dic = self._obtener_nombres_columnas_busqueda_df(\n",
        "                self.datos_diccionario, self.indices_columnas_busqueda_dic, \"diccionario (búsqueda)\"\n",
        "            )\n",
        "            if not cols_dic:\n",
        "                return None, OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DICC, None, err_cols_dic\n",
        "\n",
        "            try:\n",
        "                fcds_obtenidos, err_proc_dic = self._procesar_busqueda_en_df_objetivo(\n",
        "                    self.datos_diccionario, cols_dic, termino_busqueda_original\n",
        "                )\n",
        "                if err_proc_dic:\n",
        "                     return None, OrigenResultados.TERMINO_INVALIDO, None, err_proc_dic\n",
        "                logger.info(f\"FCDs: {len(fcds_obtenidos) if fcds_obtenidos is not None else 0}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(\"Error buscando en diccionario.\")\n",
        "                return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, None, f\"Error interno (dic): {e}\"\n",
        "\n",
        "            if self.datos_descripcion is None:\n",
        "                return None, OrigenResultados.ERROR_CARGA_DESCRIPCION, fcds_obtenidos, \"Descripciones no cargadas.\"\n",
        "\n",
        "            if fcds_obtenidos is None or fcds_obtenidos.empty:\n",
        "                return df_vacio_desc, OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC, fcds_obtenidos, None\n",
        "\n",
        "            terms_fcd = self._extraer_terminos_diccionario(fcds_obtenidos, cols_dic)\n",
        "            if not terms_fcd:\n",
        "                return df_vacio_desc, OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS, fcds_obtenidos, None\n",
        "\n",
        "            try:\n",
        "                term_or_desc = \" | \".join(terms_fcd)\n",
        "                cols_desc_fcd, err_cols_desc_fcd = self._obtener_nombres_columnas_busqueda_df(\n",
        "                     self.datos_descripcion, [], \"descripciones (vía FCDs)\"\n",
        "                )\n",
        "                if not cols_desc_fcd:\n",
        "                    return None, OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DESC, fcds_obtenidos, err_cols_desc_fcd\n",
        "\n",
        "                res_desc_via_dic, err_proc_desc_fcd = self._procesar_busqueda_en_df_objetivo(\n",
        "                    self.datos_descripcion, cols_desc_fcd, term_or_desc\n",
        "                )\n",
        "                if err_proc_desc_fcd:\n",
        "                    return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, fcds_obtenidos, f\"Error (desc vía FCD): {err_proc_desc_fcd}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(\"Error buscando términos de FCDs en descripciones.\")\n",
        "                return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, fcds_obtenidos, f\"Error interno (desc vía FCD): {e}\"\n",
        "\n",
        "            if res_desc_via_dic is None or res_desc_via_dic.empty:\n",
        "                return df_vacio_desc, OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC, fcds_obtenidos, None\n",
        "            return res_desc_via_dic, OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC, fcds_obtenidos, None\n",
        "\n",
        "        else: # Búsqueda directa\n",
        "            if self.datos_descripcion is None:\n",
        "                return None, OrigenResultados.ERROR_CARGA_DESCRIPCION, None, \"Descripciones no cargadas.\"\n",
        "\n",
        "            cols_desc_directo, err_cols_desc_directo = self._obtener_nombres_columnas_busqueda_df(\n",
        "                self.datos_descripcion, [], \"descripciones (directa)\"\n",
        "            )\n",
        "            if not cols_desc_directo:\n",
        "                return None, OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DESC, None, err_cols_desc_directo\n",
        "\n",
        "            try:\n",
        "                res_directos, err_proc_desc_directo = self._procesar_busqueda_en_df_objetivo(\n",
        "                    self.datos_descripcion, cols_desc_directo, termino_busqueda_original\n",
        "                )\n",
        "                if err_proc_desc_directo:\n",
        "                    return None, OrigenResultados.TERMINO_INVALIDO, None, err_proc_desc_directo\n",
        "                logger.info(f\"Resultados directos: {len(res_directos) if res_directos is not None else 0}\")\n",
        "            except Exception as e:\n",
        "                logger.exception(\"Error buscando directamente en descripciones.\")\n",
        "                return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, None, f\"Error interno (desc directa): {e}\"\n",
        "\n",
        "            if res_directos is None or res_directos.empty:\n",
        "                return df_vacio_desc, OrigenResultados.DIRECTO_DESCRIPCION_VACIA, None, None\n",
        "            return res_directos, OrigenResultados.DIRECTO_DESCRIPCION_CON_RESULTADOS, None, None\n",
        "\n",
        "    def _extraer_terminos_diccionario(self, df_coincidencias: pd.DataFrame, cols_nombres: List[str]) -> Set[str]:\n",
        "        terminos_clave: Set[str] = set()\n",
        "        if df_coincidencias is None or df_coincidencias.empty or not cols_nombres:\n",
        "            return terminos_clave\n",
        "\n",
        "        cols_validas = [c for c in cols_nombres if c in df_coincidencias.columns]\n",
        "        if not cols_validas:\n",
        "            logger.warning(\"Columnas de diccionario no existen en coincidencias.\")\n",
        "            return terminos_clave\n",
        "\n",
        "        for col_nombre in cols_validas:\n",
        "            try:\n",
        "                for texto_celda in df_coincidencias[col_nombre].dropna().astype(str):\n",
        "                    palabras = self.extractor_magnitud._normalizar_texto(texto_celda).split()\n",
        "                    terminos_clave.update(p for p in palabras if len(p) > 2 and p.isalnum())\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error extrayendo términos de col '{col_nombre}': {e}\")\n",
        "\n",
        "        logger.info(f\"{len(terminos_clave)} términos extraídos del diccionario para búsqueda secundaria.\")\n",
        "        if terminos_clave: logger.debug(f\"Términos clave (muestra): {list(terminos_clave)[:10]}...\")\n",
        "        return terminos_clave"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "CPVmX7apc7yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. `interfaz_grafica.py`"
      ],
      "metadata": {
        "id": "cT1C3DxKc7yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interfaz_grafica.py\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox, filedialog\n",
        "import pandas as pd\n",
        "import platform\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "from motor_busqueda import MotorBusqueda\n",
        "from enums import OrigenResultados\n",
        "from config import CONFIG_FILE_NAME # Importar el nombre del archivo de configuración\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class InterfazGrafica(tk.Tk):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.title(\"Buscador Avanzado (v0.7.1 - Mapeo Magnitudes)\")\n",
        "        self.geometry(\"1250x800\") # Considerar mover a config.py\n",
        "\n",
        "        self.config = self._cargar_configuracion()\n",
        "        indices_cfg = self.config.get(\"indices_columnas_busqueda_dic\", [])\n",
        "        self.motor = MotorBusqueda(indices_diccionario_cfg=indices_cfg)\n",
        "\n",
        "        self.resultados_actuales: Optional[pd.DataFrame] = None\n",
        "        self.texto_busqueda_var = tk.StringVar(self)\n",
        "        self.texto_busqueda_var.trace_add(\"write\", self._on_texto_busqueda_change)\n",
        "        self.ultimo_termino_buscado: Optional[str] = None\n",
        "        self.reglas_guardadas: List[Dict[str, Any]] = []\n",
        "\n",
        "        self.fcds_de_ultima_busqueda: Optional[pd.DataFrame] = None\n",
        "        self.desc_finales_de_ultima_busqueda: Optional[pd.DataFrame] = None\n",
        "\n",
        "        self.origen_principal_resultados: OrigenResultados = OrigenResultados.NINGUNO\n",
        "        self.color_fila_par = \"white\"; self.color_fila_impar = \"#f0f0f0\"\n",
        "        self.op_buttons: Dict[str, ttk.Button] = {}\n",
        "\n",
        "        self._configurar_estilo_ttk()\n",
        "        self._crear_widgets()\n",
        "        self._configurar_grid()\n",
        "        self._configurar_eventos()\n",
        "        self._configurar_tags_treeview()\n",
        "        self._configurar_orden_tabla(self.tabla_resultados)\n",
        "        self._configurar_orden_tabla(self.tabla_diccionario)\n",
        "\n",
        "        self._actualizar_estado(\"Listo. Cargue Diccionario y Descripciones.\")\n",
        "        self._deshabilitar_botones_operadores()\n",
        "        self._actualizar_botones_estado_general()\n",
        "        logger.info(\"Interfaz Gráfica (v0.7.1 - Mapeo) inicializada.\")\n",
        "\n",
        "    def _on_texto_busqueda_change(self, var_name: str, index: str, mode: str):\n",
        "        self._actualizar_estado_botones_operadores()\n",
        "\n",
        "    def _cargar_configuracion(self) -> Dict:\n",
        "        config = {}\n",
        "        if os.path.exists(CONFIG_FILE_NAME): # Usar constante de config.py\n",
        "            try:\n",
        "                with open(CONFIG_FILE_NAME, 'r', encoding='utf-8') as f: config = json.load(f)\n",
        "                logger.info(f\"Configuración cargada desde: {CONFIG_FILE_NAME}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error al cargar config: {e}\")\n",
        "        else:\n",
        "            logger.info(f\"Archivo de configuración '{CONFIG_FILE_NAME}' no encontrado. Se creará al cerrar.\")\n",
        "\n",
        "        last_dic_path_str = config.get(\"last_dic_path\")\n",
        "        config[\"last_dic_path\"] = str(Path(last_dic_path_str)) if last_dic_path_str else None\n",
        "        last_desc_path_str = config.get(\"last_desc_path\")\n",
        "        config[\"last_desc_path\"] = str(Path(last_desc_path_str)) if last_desc_path_str else None\n",
        "        config.setdefault(\"indices_columnas_busqueda_dic\", [])\n",
        "        return config\n",
        "\n",
        "    def _guardar_configuracion(self):\n",
        "        self.config[\"last_dic_path\"] = str(self.motor.archivo_diccionario_actual) if self.motor.archivo_diccionario_actual else None\n",
        "        self.config[\"last_desc_path\"] = str(self.motor.archivo_descripcion_actual) if self.motor.archivo_descripcion_actual else None\n",
        "        self.config[\"indices_columnas_busqueda_dic\"] = self.motor.indices_columnas_busqueda_dic\n",
        "        try:\n",
        "            with open(CONFIG_FILE_NAME, 'w', encoding='utf-8') as f: # Usar constante de config.py\n",
        "                json.dump(self.config, f, indent=4)\n",
        "            logger.info(f\"Configuración guardada en: {CONFIG_FILE_NAME}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error al guardar config: {e}\")\n",
        "            messagebox.showerror(\"Error Configuración\", f\"No se pudo guardar config:\\n{e}\")\n",
        "\n",
        "    def _configurar_estilo_ttk(self):\n",
        "        style = ttk.Style(self); themes = style.theme_names(); os_name = platform.system()\n",
        "        prefs = {\"Windows\":[\"vista\",\"xpnative\",\"clam\"],\"Darwin\":[\"aqua\",\"clam\"],\"Linux\":[\"clam\",\"alt\",\"default\"]}\n",
        "        theme_to_use = next((t for t in prefs.get(os_name, [\"clam\",\"default\"]) if t in themes), None)\n",
        "        if not theme_to_use:\n",
        "            theme_to_use = style.theme_use() if style.theme_use() else (\"default\" if \"default\" in themes else (themes[0] if themes else None))\n",
        "        if theme_to_use:\n",
        "            logger.info(f\"Aplicando tema TTK: {theme_to_use}\")\n",
        "            try:\n",
        "                style.theme_use(theme_to_use)\n",
        "                style.configure(\"Operator.TButton\", padding=(2, 1), font=('TkDefaultFont', 9))\n",
        "            except tk.TclError as e: logger.warning(f\"No se pudo aplicar tema '{theme_to_use}': {e}.\")\n",
        "        else: logger.warning(\"No se encontró tema TTK disponible.\")\n",
        "\n",
        "    def _crear_widgets(self):\n",
        "        self.marco_controles = ttk.LabelFrame(self, text=\"Controles\")\n",
        "        self.btn_cargar_diccionario = ttk.Button(self.marco_controles, text=\"Cargar Diccionario\", command=self._cargar_diccionario)\n",
        "        self.lbl_dic_cargado = ttk.Label(self.marco_controles, text=\"Dic: Ninguno\", width=20, anchor=tk.W, relief=tk.SUNKEN, borderwidth=1)\n",
        "        self.btn_cargar_descripciones = ttk.Button(self.marco_controles, text=\"Cargar Descripciones\", command=self._cargar_excel_descripcion)\n",
        "        self.lbl_desc_cargado = ttk.Label(self.marco_controles, text=\"Desc: Ninguno\", width=20, anchor=tk.W, relief=tk.SUNKEN, borderwidth=1)\n",
        "\n",
        "        self.frame_ops = ttk.Frame(self.marco_controles)\n",
        "        op_buttons_defs = [\n",
        "            (\"+\", \"+\"), (\"|\", \"|\"), (\"#\", \"#\"), (\">\", \">\"),\n",
        "            (\"<\", \"<\"), (\"≥\", \">=\"), (\"≤\", \"<=\"), (\"-\", \"-\")\n",
        "        ]\n",
        "        for i, (text, op_val) in enumerate(op_buttons_defs):\n",
        "            btn = ttk.Button(\n",
        "                self.frame_ops, text=text,\n",
        "                command=lambda op=op_val: self._insertar_operador_validado(op),\n",
        "                style=\"Operator.TButton\", width=3\n",
        "            )\n",
        "            btn.grid(row=0, column=i, padx=1, pady=1, sticky=\"nsew\")\n",
        "            self.op_buttons[op_val] = btn\n",
        "\n",
        "        self.entrada_busqueda = ttk.Entry(self.marco_controles, width=50, textvariable=self.texto_busqueda_var)\n",
        "        self.btn_buscar = ttk.Button(self.marco_controles, text=\"Buscar\", command=self._ejecutar_busqueda)\n",
        "        self.btn_salvar_regla = ttk.Button(self.marco_controles, text=\"Salvar Regla\", command=self._salvar_regla_actual)\n",
        "        self.btn_ayuda = ttk.Button(self.marco_controles, text=\"?\", command=self._mostrar_ayuda, width=3)\n",
        "        self.btn_exportar = ttk.Button(self.marco_controles, text=\"Exportar\", command=self._exportar_resultados)\n",
        "\n",
        "        self.lbl_tabla_diccionario = ttk.Label(self, text=\"Vista Previa Diccionario:\")\n",
        "        self.lbl_tabla_resultados = ttk.Label(self, text=\"Resultados / Descripciones:\")\n",
        "\n",
        "        self.frame_tabla_diccionario = ttk.Frame(self)\n",
        "        self.tabla_diccionario = ttk.Treeview(self.frame_tabla_diccionario, show=\"headings\", height=8)\n",
        "        self.scrolly_diccionario = ttk.Scrollbar(self.frame_tabla_diccionario, orient=\"vertical\", command=self.tabla_diccionario.yview)\n",
        "        self.scrollx_diccionario = ttk.Scrollbar(self.frame_tabla_diccionario, orient=\"horizontal\", command=self.tabla_diccionario.xview)\n",
        "        self.tabla_diccionario.configure(yscrollcommand=self.scrolly_diccionario.set, xscrollcommand=self.scrollx_diccionario.set)\n",
        "\n",
        "        self.frame_tabla_resultados = ttk.Frame(self)\n",
        "        self.tabla_resultados = ttk.Treeview(self.frame_tabla_resultados, show=\"headings\")\n",
        "        self.scrolly_resultados = ttk.Scrollbar(self.frame_tabla_resultados, orient=\"vertical\", command=self.tabla_resultados.yview)\n",
        "        self.scrollx_resultados = ttk.Scrollbar(self.frame_tabla_resultados, orient=\"horizontal\", command=self.tabla_resultados.xview)\n",
        "        self.tabla_resultados.configure(yscrollcommand=self.scrolly_resultados.set, xscrollcommand=self.scrollx_resultados.set)\n",
        "\n",
        "        self.barra_estado = ttk.Label(self, text=\"\", relief=tk.SUNKEN, anchor=tk.W, borderwidth=1)\n",
        "        self._actualizar_etiquetas_archivos()\n",
        "\n",
        "    def _configurar_grid(self):\n",
        "        self.grid_rowconfigure(2, weight=1); self.grid_rowconfigure(4, weight=3)\n",
        "        self.grid_columnconfigure(0, weight=1)\n",
        "        self.marco_controles.grid(row=0, column=0, sticky=\"new\", padx=10, pady=(10, 5))\n",
        "        self.marco_controles.grid_columnconfigure(1, weight=1)\n",
        "        self.marco_controles.grid_columnconfigure(3, weight=1)\n",
        "\n",
        "        self.btn_cargar_diccionario.grid(row=0, column=0, padx=(5,0), pady=5, sticky=\"w\")\n",
        "        self.lbl_dic_cargado.grid(row=0, column=1, padx=(2,10), pady=5, sticky=\"ew\")\n",
        "        self.btn_cargar_descripciones.grid(row=0, column=2, padx=(5,0), pady=5, sticky=\"w\")\n",
        "        self.lbl_desc_cargado.grid(row=0, column=3, padx=(2,5), pady=5, sticky=\"ew\")\n",
        "\n",
        "        self.frame_ops.grid(row=1, column=0, columnspan=4, padx=5, pady=(5,0), sticky=\"ew\")\n",
        "        for i in range(len(self.op_buttons)): self.frame_ops.grid_columnconfigure(i, weight=1)\n",
        "\n",
        "        self.entrada_busqueda.grid(row=2, column=0, columnspan=2, padx=5, pady=(0,5), sticky=\"ew\")\n",
        "        self.btn_buscar.grid(row=2, column=2, padx=(2,0), pady=(0,5), sticky=\"w\")\n",
        "        self.btn_salvar_regla.grid(row=2, column=3, padx=(2,0), pady=(0,5), sticky=\"w\")\n",
        "        self.btn_ayuda.grid(row=2, column=4, padx=(2,0), pady=(0,5), sticky=\"w\")\n",
        "        self.btn_exportar.grid(row=2, column=5, padx=(10, 5), pady=(0,5), sticky=\"e\")\n",
        "\n",
        "        self.lbl_tabla_diccionario.grid(row=1, column=0, sticky=\"sw\", padx=10, pady=(10, 0))\n",
        "        self.frame_tabla_diccionario.grid(row=2, column=0, sticky=\"nsew\", padx=10, pady=(0, 10))\n",
        "        self.frame_tabla_diccionario.grid_rowconfigure(0, weight=1); self.frame_tabla_diccionario.grid_columnconfigure(0, weight=1)\n",
        "        self.tabla_diccionario.grid(row=0, column=0, sticky=\"nsew\"); self.scrolly_diccionario.grid(row=0, column=1, sticky=\"ns\"); self.scrollx_diccionario.grid(row=1, column=0, sticky=\"ew\")\n",
        "\n",
        "        self.lbl_tabla_resultados.grid(row=3, column=0, sticky=\"sw\", padx=10, pady=(0, 0))\n",
        "        self.frame_tabla_resultados.grid(row=4, column=0, sticky=\"nsew\", padx=10, pady=(0, 10))\n",
        "        self.frame_tabla_resultados.grid_rowconfigure(0, weight=1); self.frame_tabla_resultados.grid_columnconfigure(0, weight=1)\n",
        "        self.tabla_resultados.grid(row=0, column=0, sticky=\"nsew\"); self.scrolly_resultados.grid(row=0, column=1, sticky=\"ns\"); self.scrollx_resultados.grid(row=1, column=0, sticky=\"ew\")\n",
        "\n",
        "        self.barra_estado.grid(row=5, column=0, sticky=\"sew\", padx=0, pady=(5, 0))\n",
        "\n",
        "    def _configurar_eventos(self):\n",
        "        self.entrada_busqueda.bind(\"<Return>\", lambda event: self._ejecutar_busqueda())\n",
        "        self.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
        "\n",
        "    def _actualizar_estado(self, mensaje: str):\n",
        "        self.barra_estado.config(text=mensaje)\n",
        "        logger.info(f\"Estado UI: {mensaje}\")\n",
        "        self.update_idletasks()\n",
        "\n",
        "    def _mostrar_ayuda(self):\n",
        "        # El texto de ayuda permanece igual, ya que la sintaxis de búsqueda para el usuario no ha cambiado.\n",
        "        ayuda = \"\"\"Sintaxis de Búsqueda:\n",
        "-------------------------------------\n",
        "- Texto simple: Busca la palabra o frase (insensible a mayús/minús y acentos). Ej: `router cisco`\n",
        "- Operadores Lógicos:\n",
        "  * `término1 + término2`: Busca filas con AMBOS (AND). Ej: `tarjeta + 16 puertos`\n",
        "  * `término1 | término2` (o `/`): Busca filas con AL MENOS UNO (OR). Ej: `modulo | SFP`\n",
        "- Comparaciones numéricas (unidad opcional, si se usa debe coincidir con mapeo interno):\n",
        "  * `>num[UNIDAD]`: Mayor. Ej: `>1000` o `>1000w`\n",
        "  * `<num[UNIDAD]`: Menor. Ej: `<50` o `<50v`\n",
        "  * `>=num[UNIDAD]` o `≥num[UNIDAD]`: Mayor o igual. Ej: `>=48a`\n",
        "  * `<=num[UNIDAD]` o `≤num[UNIDAD]`: Menor o igual. Ej: `<=10.5w`\n",
        "- Rangos numéricos (unidad opcional, ambos extremos incluidos):\n",
        "  * `num1-num2[UNIDAD]`: Entre num1 y num2. Ej: `10-20` o `50-100V`\n",
        "- Negación (excluir):\n",
        "  * `#término`: `término` puede ser texto, comparación o rango.\n",
        "    Ej: `switch + #gestionable`\n",
        "    Ej: `tarjeta + #>8 puertos`\n",
        "\n",
        "Modo de Búsqueda:\n",
        "1. El término se busca primero en el Diccionario.\n",
        "2. Si hay coincidencias (FCDs), se extraen textos y se buscan en Descripciones.\n",
        "3. Si no, se preguntará para buscar el término original directamente en Descripciones.\n",
        "4. Búsqueda vacía: Muestra todas las descripciones.\n",
        "\"\"\"\n",
        "        messagebox.showinfo(\"Ayuda - Sintaxis de Búsqueda\", ayuda)\n",
        "\n",
        "    def _configurar_tags_treeview(self):\n",
        "        for tabla in [self.tabla_diccionario, self.tabla_resultados]:\n",
        "            tabla.tag_configure('par', background=self.color_fila_par)\n",
        "            tabla.tag_configure('impar', background=self.color_fila_impar)\n",
        "\n",
        "    def _configurar_orden_tabla(self, tabla: ttk.Treeview):\n",
        "        cols = tabla[\"columns\"]\n",
        "        if cols:\n",
        "            for col in cols:\n",
        "                tabla.heading(col, text=str(col), anchor=tk.W,\n",
        "                              command=lambda c=col, t=tabla: self._ordenar_columna(t, c, False))\n",
        "\n",
        "    def _ordenar_columna(self, tabla: ttk.Treeview, col: str, reverse: bool):\n",
        "        df_para_ordenar = None\n",
        "        if tabla == self.tabla_diccionario:\n",
        "            df_para_ordenar = self.motor.datos_diccionario\n",
        "        elif tabla == self.tabla_resultados:\n",
        "            df_para_ordenar = self.resultados_actuales\n",
        "\n",
        "        if df_para_ordenar is None or df_para_ordenar.empty or col not in df_para_ordenar.columns:\n",
        "            logging.debug(f\"No se puede ordenar tabla por columna '{col}'.\")\n",
        "            tabla.heading(col, command=lambda c=col, t=tabla: self._ordenar_columna(t, c, not reverse))\n",
        "            return\n",
        "\n",
        "        logging.info(f\"Ordenando tabla por columna '{col}', descendente={reverse}\")\n",
        "        try:\n",
        "            col_to_sort_by = df_para_ordenar[col]\n",
        "            try: # Intento de orden numérico inteligente\n",
        "                nan_mask = pd.to_numeric(col_to_sort_by, errors='coerce').isna()\n",
        "                numeric_part = col_to_sort_by[~nan_mask]\n",
        "                nan_part = col_to_sort_by[nan_mask]\n",
        "\n",
        "                if not numeric_part.empty:\n",
        "                    temp_numeric = pd.to_numeric(numeric_part, errors='coerce')\n",
        "                    if not temp_numeric.isna().all():\n",
        "                        sorted_numeric_indices = temp_numeric.sort_values(ascending=not reverse).index\n",
        "                        final_order_indices = sorted_numeric_indices.tolist() + nan_part.index.tolist()\n",
        "                        df_ordenado = df_para_ordenar.loc[final_order_indices]\n",
        "                    else: raise ValueError(\"No convertible a numérico fiable\")\n",
        "                else:\n",
        "                    df_ordenado = df_para_ordenar.sort_values(by=col, ascending=not reverse, na_position='last', key=lambda x: x.astype(str).str.lower())\n",
        "            except (ValueError, TypeError): # Fallback a ordenación de texto\n",
        "                df_ordenado = df_para_ordenar.sort_values(\n",
        "                    by=col, ascending=not reverse, na_position='last',\n",
        "                    key=lambda x: x.astype(str).str.lower() if pd.api.types.is_string_dtype(x) or pd.api.types.is_object_dtype(x) else x\n",
        "                )\n",
        "\n",
        "            if tabla == self.tabla_diccionario:\n",
        "                self.motor.datos_diccionario = df_ordenado\n",
        "                self._actualizar_tabla(tabla, df_ordenado, limite_filas=100)\n",
        "            elif tabla == self.tabla_resultados:\n",
        "                self.resultados_actuales = df_ordenado\n",
        "                self._actualizar_tabla(tabla, df_ordenado)\n",
        "\n",
        "            tabla.heading(col, command=lambda c=col, t=tabla: self._ordenar_columna(t, c, not reverse))\n",
        "            self._actualizar_estado(f\"Tabla ordenada por '{col}' ({'Asc' if not reverse else 'Desc'}).\")\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Error ordenando por columna '{col}'\")\n",
        "            messagebox.showerror(\"Error al Ordenar\", f\"No se pudo ordenar por '{col}':\\n{e}\")\n",
        "            tabla.heading(col, command=lambda c=col, t=tabla: self._ordenar_columna(t, c, False))\n",
        "\n",
        "\n",
        "    def _actualizar_tabla(self, tabla: ttk.Treeview, datos: Optional[pd.DataFrame], limite_filas: Optional[int] = None, columnas_a_mostrar: Optional[List[str]] = None):\n",
        "        is_diccionario = tabla == self.tabla_diccionario\n",
        "        logger.debug(f\"Actualizando tabla {'Diccionario' if is_diccionario else 'Resultados'}.\")\n",
        "        try:\n",
        "            for i in tabla.get_children(): tabla.delete(i)\n",
        "        except tk.TclError as e: logger.warning(f\"Error Tcl limpiando tabla: {e}\"); pass\n",
        "        tabla[\"columns\"] = ()\n",
        "\n",
        "        if datos is None or datos.empty:\n",
        "            logger.debug(\"Sin datos para mostrar en tabla.\")\n",
        "            self._configurar_orden_tabla(tabla)\n",
        "            return\n",
        "\n",
        "        cols_df = list(datos.columns)\n",
        "        cols_finales = [c for c in (columnas_a_mostrar or cols_df) if c in cols_df] or cols_df\n",
        "\n",
        "        if not cols_finales:\n",
        "            logger.warning(\"DataFrame sin columnas o columnas seleccionadas no existen.\")\n",
        "            self._configurar_orden_tabla(tabla)\n",
        "            return\n",
        "\n",
        "        df_vista = datos[cols_finales]\n",
        "        tabla[\"columns\"] = tuple(cols_finales)\n",
        "\n",
        "        for col in cols_finales:\n",
        "            tabla.heading(col, text=str(col), anchor=tk.W)\n",
        "            try:\n",
        "                col_str = df_vista[col].astype(str)\n",
        "                ancho_cont = col_str.str.len().max() if not col_str.empty else 0\n",
        "                ancho_cab = len(str(col))\n",
        "                ancho = max(70, min(int(max(ancho_cab * 8, ancho_cont * 6.5) + 25), 400))\n",
        "                tabla.column(col, anchor=tk.W, width=ancho, minwidth=70)\n",
        "            except Exception:\n",
        "                tabla.column(col, anchor=tk.W, width=100, minwidth=50)\n",
        "\n",
        "        num_iterar = limite_filas if is_diccionario and limite_filas is not None else len(df_vista)\n",
        "        df_iterar = df_vista.head(num_iterar)\n",
        "\n",
        "        for i, (_, row) in enumerate(df_iterar.iterrows()):\n",
        "            vals = [str(v) if pd.notna(v) else \"\" for v in row.values]\n",
        "            tag = 'par' if i % 2 == 0 else 'impar'\n",
        "            try:\n",
        "                tabla.insert(\"\", \"end\", values=vals, tags=(tag,))\n",
        "            except tk.TclError:\n",
        "                try:\n",
        "                    vals_ascii = [v.encode('ascii', 'ignore').decode('ascii') for v in vals]\n",
        "                    tabla.insert(\"\", \"end\", values=vals_ascii, tags=(tag,))\n",
        "                except Exception as e_inner:\n",
        "                    logger.error(f\"Fallo fallback ASCII fila {i}: {e_inner}\")\n",
        "\n",
        "        self._configurar_orden_tabla(tabla)\n",
        "\n",
        "    def _actualizar_etiquetas_archivos(self):\n",
        "        dic_p = self.motor.archivo_diccionario_actual\n",
        "        desc_p = self.motor.archivo_descripcion_actual\n",
        "        dic_n = dic_p.name if dic_p else \"Ninguno\"\n",
        "        desc_n = desc_p.name if desc_p else \"Ninguno\"\n",
        "\n",
        "        max_l = 25\n",
        "        dic_d = f\"Dic: {dic_n}\" if len(dic_n) <= max_l else f\"Dic: ...{dic_n[-(max_l-4):]}\"\n",
        "        desc_d = f\"Desc: {desc_n}\" if len(desc_n) <= max_l else f\"Desc: ...{desc_n[-(max_l-4):]}\"\n",
        "\n",
        "        self.lbl_dic_cargado.config(text=dic_d, foreground=\"green\" if dic_p else \"red\")\n",
        "        self.lbl_desc_cargado.config(text=desc_d, foreground=\"green\" if desc_p else \"red\")\n",
        "\n",
        "    def _actualizar_botones_estado_general(self):\n",
        "        dic_ok = self.motor.datos_diccionario is not None\n",
        "        desc_ok = self.motor.datos_descripcion is not None\n",
        "\n",
        "        if dic_ok or desc_ok: self._actualizar_estado_botones_operadores()\n",
        "        else: self._deshabilitar_botones_operadores()\n",
        "\n",
        "        self.btn_buscar['state'] = 'normal' if dic_ok and desc_ok else 'disabled'\n",
        "\n",
        "        salvar_ok = False\n",
        "        if self.ultimo_termino_buscado and self.origen_principal_resultados != OrigenResultados.NINGUNO:\n",
        "            if self.origen_principal_resultados.es_via_diccionario:\n",
        "                if (self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty) or \\\n",
        "                   (self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and \\\n",
        "                    self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC):\n",
        "                    salvar_ok = True\n",
        "            elif self.origen_principal_resultados.es_directo_descripcion or \\\n",
        "                 self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA:\n",
        "                if self.desc_finales_de_ultima_busqueda is not None: salvar_ok = True\n",
        "\n",
        "        self.btn_salvar_regla['state'] = 'normal' if salvar_ok else 'disabled'\n",
        "        self.btn_exportar['state'] = 'normal' if self.reglas_guardadas else 'disabled'\n",
        "\n",
        "    def _cargar_diccionario(self):\n",
        "        last_dir = str(Path(self.config.get(\"last_dic_path\",\"\")).parent) if self.config.get(\"last_dic_path\") and Path(self.config.get(\"last_dic_path\",\"\")).exists() else os.getcwd()\n",
        "        ruta = filedialog.askopenfilename(title=\"Cargar Diccionario\", filetypes=[(\"Excel\", \"*.xlsx *.xls\")], initialdir=last_dir)\n",
        "        if not ruta: return\n",
        "\n",
        "        self._actualizar_estado(f\"Cargando diccionario: {Path(ruta).name}...\")\n",
        "        self._actualizar_tabla(self.tabla_diccionario, None); self._actualizar_tabla(self.tabla_resultados, None)\n",
        "        self.resultados_actuales = self.fcds_de_ultima_busqueda = self.desc_finales_de_ultima_busqueda = None\n",
        "        self.origen_principal_resultados = OrigenResultados.NINGUNO\n",
        "\n",
        "        exito, msg = self.motor.cargar_excel_diccionario(ruta)\n",
        "        if exito:\n",
        "            self.config[\"last_dic_path\"] = ruta; self._guardar_configuracion()\n",
        "            df_dic = self.motor.datos_diccionario\n",
        "            if df_dic is not None:\n",
        "                n_filas = len(df_dic)\n",
        "                cols_b, _ = self.motor._obtener_nombres_columnas_busqueda_df(df_dic, self.motor.indices_columnas_busqueda_dic, \"dic (preview)\")\n",
        "                idxs_str = ', '.join(map(str, self.motor.indices_columnas_busqueda_dic or [])) if self.motor.indices_columnas_busqueda_dic and self.motor.indices_columnas_busqueda_dic != [-1] else \"Todas Texto\"\n",
        "                lbl_txt = f\"Vista Previa Dic ({n_filas} filas)\" + (f\" (Cols: {', '.join(cols_b)} - Idx: {idxs_str})\" if cols_b else \"\")\n",
        "                self.lbl_tabla_diccionario.config(text=lbl_txt)\n",
        "                self._actualizar_tabla(self.tabla_diccionario, df_dic, limite_filas=100, columnas_a_mostrar=cols_b)\n",
        "                self.title(f\"Buscador - Dic: {Path(ruta).name}\")\n",
        "                self._actualizar_estado(f\"Diccionario '{Path(ruta).name}' ({n_filas} filas) cargado.\")\n",
        "        else:\n",
        "            self._actualizar_estado(f\"Error cargando diccionario: {msg or 'Desconocido'}\")\n",
        "            if msg: messagebox.showerror(\"Error Carga Diccionario\", msg)\n",
        "            self.title(\"Buscador Avanzado (v0.7.1 - Mapeo Magnitudes)\")\n",
        "        self._actualizar_etiquetas_archivos()\n",
        "        self._actualizar_botones_estado_general()\n",
        "\n",
        "    def _cargar_excel_descripcion(self):\n",
        "        last_dir = str(Path(self.config.get(\"last_desc_path\",\"\")).parent) if self.config.get(\"last_desc_path\") and Path(self.config.get(\"last_desc_path\",\"\")).exists() else os.getcwd()\n",
        "        ruta = filedialog.askopenfilename(title=\"Cargar Descripciones\", filetypes=[(\"Excel\", \"*.xlsx *.xls\")], initialdir=last_dir)\n",
        "        if not ruta: return\n",
        "\n",
        "        self._actualizar_estado(f\"Cargando descripciones: {Path(ruta).name}...\")\n",
        "        self.resultados_actuales = self.desc_finales_de_ultima_busqueda = None\n",
        "        self.origen_principal_resultados = OrigenResultados.NINGUNO\n",
        "        self._actualizar_tabla(self.tabla_resultados, None)\n",
        "\n",
        "        exito, msg = self.motor.cargar_excel_descripcion(ruta)\n",
        "        if exito:\n",
        "            self.config[\"last_desc_path\"] = ruta; self._guardar_configuracion()\n",
        "            df_desc = self.motor.datos_descripcion\n",
        "            if df_desc is not None:\n",
        "                n_filas = len(df_desc)\n",
        "                self._actualizar_estado(f\"Descripciones '{Path(ruta).name}' ({n_filas} filas) cargadas.\")\n",
        "                self._actualizar_tabla(self.tabla_resultados, df_desc)\n",
        "                dic_title = Path(self.motor.archivo_diccionario_actual or \"\").name or \"N/A\"\n",
        "                self.title(f\"Buscador - Dic: {dic_title} | Desc: {Path(ruta).name}\")\n",
        "        else:\n",
        "            self._actualizar_estado(f\"Error cargando descripciones: {msg or 'Desconocido'}\")\n",
        "            if msg: messagebox.showerror(\"Error Carga Descripciones\", msg)\n",
        "            dic_title = Path(self.motor.archivo_diccionario_actual or \"\").name or \"N/A\"\n",
        "            self.title(f\"Buscador - Dic: {dic_title} | Desc: N/A\" if self.motor.archivo_diccionario_actual else \"Buscador Avanzado (v0.7.1)\")\n",
        "        self._actualizar_etiquetas_archivos()\n",
        "        self._actualizar_botones_estado_general()\n",
        "\n",
        "    def _ejecutar_busqueda(self):\n",
        "        if not self.motor.datos_diccionario or not self.motor.datos_descripcion:\n",
        "            messagebox.showwarning(\"Archivos Faltantes\", \"Cargue Diccionario y Descripciones.\")\n",
        "            return\n",
        "\n",
        "        term = self.texto_busqueda_var.get()\n",
        "        self.ultimo_termino_buscado = term\n",
        "        self.resultados_actuales = self.fcds_de_ultima_busqueda = self.desc_finales_de_ultima_busqueda = None\n",
        "        self.origen_principal_resultados = OrigenResultados.NINGUNO\n",
        "        self._actualizar_tabla(self.tabla_resultados, None)\n",
        "        self._actualizar_estado(f\"Buscando '{term}'...\")\n",
        "\n",
        "        res_df, origen, fcds, err_msg = self.motor.buscar(term, True)\n",
        "        self.fcds_de_ultima_busqueda = fcds; self.origen_principal_resultados = origen\n",
        "        df_desc_cols = self.motor.datos_descripcion.columns if self.motor.datos_descripcion is not None else []\n",
        "\n",
        "        if err_msg and (origen.es_error_operacional or origen.es_termino_invalido) : # Error crítico del motor\n",
        "             messagebox.showerror(\"Error de Búsqueda (Motor)\", f\"Error: {err_msg}\")\n",
        "             self._actualizar_estado(f\"Error en motor: {err_msg}\")\n",
        "             self.resultados_actuales = pd.DataFrame(columns=df_desc_cols)\n",
        "        elif origen.es_error_carga or origen.es_error_configuracion :\n",
        "             msg_sh = err_msg or f\"Error: {origen.name}\"\n",
        "             messagebox.showerror(\"Error de Búsqueda\", msg_sh)\n",
        "             self._actualizar_estado(msg_sh)\n",
        "             self.resultados_actuales = pd.DataFrame(columns=df_desc_cols)\n",
        "        elif origen == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC:\n",
        "            self.resultados_actuales = res_df\n",
        "            self._actualizar_estado(f\"'{term}': {len(fcds or [])} en Dic, {len(res_df or [])} en Desc.\")\n",
        "        elif origen in [OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC, OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS] or \\\n",
        "             (fcds is not None and fcds.empty and origen == OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC):\n",
        "            self.resultados_actuales = res_df # DF vacío\n",
        "            msg_fcd_info = f\"{len(fcds or [])} coincidencias en Diccionario\" if fcds is not None and not fcds.empty else \"Ninguna coincidencia en Diccionario\"\n",
        "            msg_desc_issue = \"pero no se extrajeron términos para Desc.\" if origen == OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS else \"sin resultados en Desc.\"\n",
        "            self._actualizar_estado(f\"'{term}': {msg_fcd_info}, {msg_desc_issue.split('.')[0]}.\")\n",
        "            if messagebox.askyesno(\"Búsqueda Alternativa\", f\"{msg_fcd_info} para '{term}', {msg_desc_issue}\\n\\nBuscar '{term}' directo en Descripciones?\"):\n",
        "                self._actualizar_estado(f\"Buscando directo '{term}' en descripciones...\")\n",
        "                res_df_dir, origen_dir, _, err_msg_dir = self.motor.buscar(term, False)\n",
        "                if err_msg_dir and (origen_dir.es_error_operacional or origen_dir.es_termino_invalido):\n",
        "                     messagebox.showerror(\"Error Búsqueda Directa\", f\"Error: {err_msg_dir}\")\n",
        "                     self._actualizar_estado(f\"Error búsqueda directa: {err_msg_dir}\")\n",
        "                elif origen_dir.es_error_carga or origen_dir.es_error_configuracion:\n",
        "                     msg_sh_dir = err_msg_dir or f\"Error en búsqueda directa: {origen_dir.name}\"\n",
        "                     messagebox.showerror(\"Error Búsqueda Directa\", msg_sh_dir)\n",
        "                     self._actualizar_estado(msg_sh_dir)\n",
        "                else:\n",
        "                    self.resultados_actuales = res_df_dir; self.origen_principal_resultados = origen_dir\n",
        "                    self.fcds_de_ultima_busqueda = None\n",
        "                    num_rdd = len(self.resultados_actuales or [])\n",
        "                    self._actualizar_estado(f\"Búsqueda directa '{term}': {num_rdd} resultados.\")\n",
        "                    if num_rdd == 0 and origen_dir == OrigenResultados.DIRECTO_DESCRIPCION_VACIA and term.strip():\n",
        "                        messagebox.showinfo(\"Información\", f\"No se encontraron resultados para '{term}' directo.\")\n",
        "        elif origen == OrigenResultados.DIRECTO_DESCRIPCION_CON_RESULTADOS :\n",
        "            self.resultados_actuales = res_df\n",
        "            self._actualizar_estado(f\"Búsqueda directa '{term}': {len(res_df or [])} resultados.\")\n",
        "        elif origen == OrigenResultados.DIRECTO_DESCRIPCION_VACIA:\n",
        "            self.resultados_actuales = res_df\n",
        "            self._actualizar_estado(f\"Búsqueda directa '{term}': 0 resultados.\")\n",
        "            if term.strip(): messagebox.showinfo(\"Información\", f\"No se encontraron resultados para '{term}' directo.\")\n",
        "\n",
        "        if self.resultados_actuales is None: self.resultados_actuales = pd.DataFrame(columns=df_desc_cols)\n",
        "        self.desc_finales_de_ultima_busqueda = self.resultados_actuales.copy()\n",
        "        self._actualizar_tabla(self.tabla_resultados, self.resultados_actuales)\n",
        "        self._actualizar_botones_estado_general()\n",
        "        if self.motor.datos_diccionario is not None and not self.motor.datos_diccionario.empty:\n",
        "            self._buscar_y_enfocar_en_preview()\n",
        "\n",
        "    def _buscar_y_enfocar_en_preview(self): # Simplificado para brevedad, la lógica es de UI\n",
        "        df_dic = self.motor.datos_diccionario\n",
        "        if df_dic is None or df_dic.empty: return\n",
        "        term_raw = self.texto_busqueda_var.get()\n",
        "        if not term_raw.strip(): return\n",
        "\n",
        "        op_n1, segs_n1 = self.motor._parsear_nivel1_or(term_raw)\n",
        "        if not segs_n1: return\n",
        "        op_n2, terms_n2 = self.motor._parsear_nivel2_and(segs_n1[0])\n",
        "        if not terms_n2: return\n",
        "        term_focus_raw = terms_n2[0][1:].strip() if terms_n2[0].startswith(\"#\") else terms_n2[0].strip()\n",
        "        if not term_focus_raw: return\n",
        "        term_focus_norm = self.motor.extractor_magnitud._normalizar_texto(term_focus_raw)\n",
        "        if not term_focus_norm: return\n",
        "\n",
        "        items_ids = self.tabla_diccionario.get_children('')\n",
        "        if not items_ids: return\n",
        "\n",
        "        logger.info(f\"Enfocando '{term_focus_norm}' en preview diccionario...\")\n",
        "        found_id = None\n",
        "        cols_preview = self.tabla_diccionario[\"columns\"] or []\n",
        "        # La lógica original para encontrar el item_id era compleja y dependía de la estructura de datos\n",
        "        # en la preview. Aquí una simplificación conceptual:\n",
        "        for item_id in items_ids:\n",
        "            try:\n",
        "                vals = self.tabla_diccionario.item(item_id, 'values')\n",
        "                if any(term_focus_norm in self.motor.extractor_magnitud._normalizar_texto(str(v)) for v in vals if v):\n",
        "                    found_id = item_id; break\n",
        "            except Exception: continue\n",
        "\n",
        "        if found_id:\n",
        "            logger.info(f\"Término '{term_focus_norm}' enfocado (ID: {found_id}).\")\n",
        "            try:\n",
        "                if self.tabla_diccionario.selection(): self.tabla_diccionario.selection_remove(self.tabla_diccionario.selection())\n",
        "                self.tabla_diccionario.selection_set(found_id); self.tabla_diccionario.see(found_id); self.tabla_diccionario.focus(found_id)\n",
        "            except Exception as e: logger.error(f\"Error enfocando item {found_id}: {e}\")\n",
        "        else: logger.info(f\"Término '{term_focus_norm}' no enfocado en preview.\")\n",
        "\n",
        "\n",
        "    def _salvar_regla_actual(self): # La lógica interna de esta función es extensa y se mantiene\n",
        "        origen_nombre = self.origen_principal_resultados.name\n",
        "        logger.info(f\"Salvando regla. Origen: {origen_nombre}, Último término: '{self.ultimo_termino_buscado}'\")\n",
        "\n",
        "        if not self.ultimo_termino_buscado and not (self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA and self.desc_finales_de_ultima_busqueda is not None):\n",
        "            messagebox.showerror(\"Error\", \"No hay término de búsqueda o resultados válidos.\"); return\n",
        "\n",
        "        term_orig_regla = self.ultimo_termino_buscado or ''\n",
        "        op_n1, segs_n1 = self.motor._parsear_nivel1_or(term_orig_regla)\n",
        "        parsed_segs = []\n",
        "        for seg in segs_n1:\n",
        "            op_n2, terms_n2 = self.motor._parsear_nivel2_and(seg)\n",
        "            parsed_segs.append({\"operador_segmento_and\": op_n2, \"terminos_analizados\": self.motor._analizar_terminos(terms_n2)})\n",
        "\n",
        "        regla_base = {'termino_busqueda_original': term_orig_regla, 'operador_principal_or': op_n1,\n",
        "                      'segmentos_parseados_para_and': parsed_segs, 'fuente_original_guardado': origen_nombre,\n",
        "                      'timestamp': pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "        salvo = False\n",
        "\n",
        "        if self.origen_principal_resultados.es_via_diccionario:\n",
        "            decision = self._mostrar_dialogo_seleccion_salvado_via_diccionario()\n",
        "            if decision['confirmed']:\n",
        "                if decision['save_fcd'] and self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty:\n",
        "                    self.reglas_guardadas.append({**regla_base, 'tipo_datos_guardados': \"COINCIDENCIAS_DICCIONARIO\", 'datos_snapshot': self.fcds_de_ultima_busqueda.to_dict('records')}); salvo = True\n",
        "                if decision['save_rfd'] and self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC:\n",
        "                    self.reglas_guardadas.append({**regla_base, 'tipo_datos_guardados': \"RESULTADOS_DESCRIPCION_VIA_DICCIONARIO\", 'datos_snapshot': self.desc_finales_de_ultima_busqueda.to_dict('records')}); salvo = True\n",
        "        elif self.origen_principal_resultados.es_directo_descripcion or self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA:\n",
        "             if self.desc_finales_de_ultima_busqueda is not None:\n",
        "                tipo = \"TODAS_LAS_DESCRIPCIONES\" if self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA and not term_orig_regla.strip() else \"RESULTADOS_DESCRIPCION_DIRECTA\"\n",
        "                self.reglas_guardadas.append({**regla_base, 'tipo_datos_guardados': tipo, 'datos_snapshot': self.desc_finales_de_ultima_busqueda.to_dict('records')}); salvo = True\n",
        "             else: messagebox.showwarning(\"Sin Datos\", \"No hay resultados de descripción para salvar.\")\n",
        "        else:\n",
        "            if self.origen_principal_resultados != OrigenResultados.NINGUNO and not (self.origen_principal_resultados.es_error_carga or self.origen_principal_resultados.es_error_configuracion or self.origen_principal_resultados.es_error_operacional or self.origen_principal_resultados.es_termino_invalido):\n",
        "                messagebox.showerror(\"Error\", f\"No se puede determinar qué salvar para origen: {origen_nombre}.\")\n",
        "            else: messagebox.showwarning(\"Nada que Salvar\", \"No hay resultados válidos para salvar.\")\n",
        "\n",
        "        if salvo: self._actualizar_estado(f\"Regla(s) guardada(s). Total: {len(self.reglas_guardadas)}.\")\n",
        "        elif self.ultimo_termino_buscado or self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA :\n",
        "            self._actualizar_estado(\"Ninguna regla salvada.\")\n",
        "        self._actualizar_botones_estado_general()\n",
        "\n",
        "\n",
        "    def _mostrar_dialogo_seleccion_salvado_via_diccionario(self) -> Dict[str, bool]: # UI, se mantiene\n",
        "        decision = {'confirmed': False, 'save_fcd': False, 'save_rfd': False}\n",
        "        dialog = tk.Toplevel(self); dialog.title(\"Seleccionar Datos a Salvar\"); dialog.geometry(\"400x200\")\n",
        "        dialog.resizable(False, False); dialog.transient(self); dialog.grab_set()\n",
        "\n",
        "        var_fcd = tk.BooleanVar(value=(self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty))\n",
        "        var_rfd = tk.BooleanVar(value=(self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC))\n",
        "\n",
        "        ttk.Label(dialog, text=\"¿Qué datos salvar de la búsqueda vía Diccionario?\").pack(pady=10, padx=10)\n",
        "        chk_fcd = ttk.Checkbutton(dialog, text=\"Coincidencias del Diccionario (FCDs)\", variable=var_fcd)\n",
        "        chk_fcd.pack(anchor=tk.W, padx=20)\n",
        "        chk_fcd['state'] = 'normal' if self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty else 'disabled'\n",
        "        chk_rfd = ttk.Checkbutton(dialog, text=\"Resultados Finales de Descripciones (RFDs)\", variable=var_rfd)\n",
        "        chk_rfd.pack(anchor=tk.W, padx=20)\n",
        "        chk_rfd['state'] = 'normal' if self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC else 'disabled'\n",
        "\n",
        "        frm_btns = ttk.Frame(dialog); frm_btns.pack(pady=15)\n",
        "        def on_ok():\n",
        "            decision.update({'confirmed': True, 'save_fcd': var_fcd.get(), 'save_rfd': var_rfd.get()})\n",
        "            if not decision['save_fcd'] and not decision['save_rfd']:\n",
        "                fcd_ok = self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty\n",
        "                rfd_ok = self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC\n",
        "                if fcd_ok or rfd_ok: messagebox.showwarning(\"Nada Seleccionado\", \"No seleccionó datos.\", parent=dialog); decision['confirmed'] = False; return\n",
        "            dialog.destroy()\n",
        "        ttk.Button(frm_btns, text=\"Confirmar\", command=on_ok).pack(side=tk.LEFT, padx=10)\n",
        "        ttk.Button(frm_btns, text=\"Cancelar\", command=dialog.destroy).pack(side=tk.LEFT, padx=10)\n",
        "\n",
        "        self.update_idletasks()\n",
        "        px, py, pw, ph = self.winfo_x(), self.winfo_y(), self.winfo_width(), self.winfo_height()\n",
        "        dw, dh = dialog.winfo_reqwidth(), dialog.winfo_reqheight()\n",
        "        dialog.geometry(f\"+{px + (pw // 2) - (dw // 2)}+{py + (ph // 2) - (dh // 2)}\")\n",
        "        self.wait_window(dialog)\n",
        "        return decision\n",
        "\n",
        "\n",
        "    def _exportar_resultados(self): # Lógica de exportación se mantiene\n",
        "        if not self.reglas_guardadas: messagebox.showwarning(\"Sin Reglas\", \"No hay reglas para exportar.\"); return\n",
        "\n",
        "        ts_export = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        f_sug = f\"exportacion_reglas_{ts_export}.xlsx\"\n",
        "        ruta_save = filedialog.asksaveasfilename(title=\"Exportar Reglas...\", initialfile=f_sug, defaultextension=\".xlsx\", filetypes=[(\"Excel\", \"*.xlsx\")])\n",
        "        if not ruta_save: self._actualizar_estado(\"Exportación cancelada.\"); return\n",
        "\n",
        "        self._actualizar_estado(\"Exportando...\"); num_r = len(self.reglas_guardadas)\n",
        "        logging.info(f\"Exportando {num_r} regla(s) a: {ruta_save}\")\n",
        "        try:\n",
        "            with pd.ExcelWriter(ruta_save, engine='openpyxl') as writer:\n",
        "                idx_export = []\n",
        "                for i, regla in enumerate(self.reglas_guardadas):\n",
        "                    tipo_short = regla.get('tipo_datos_guardados', 'DATOS').replace(\"RESULTADOS_DESCRIPCION_\", \"DESC_\").replace(\"COINCIDENCIAS_DICCIONARIO\", \"FCD\")[:10]\n",
        "                    term_short = self._sanitizar_nombre_archivo(regla.get('termino_busqueda_original','S_T'),10)\n",
        "                    id_hoja = f\"R{i+1}_{term_short}_{tipo_short}\"[:31]\n",
        "                    idx_export.append({\"ID_Regla_Hoja_Destino\": id_hoja, \"Termino_Busqueda_Original\": regla.get('termino_busqueda_original', 'N/A'),\n",
        "                                       \"Operador_Principal_OR\": regla.get('operador_principal_or', 'N/A'), \"Tipo_Datos_Guardados\": regla.get('tipo_datos_guardados', 'N/A'),\n",
        "                                       \"Fuente_Original_Resultados\": regla.get('fuente_original_guardado', 'N/A'), \"Timestamp_Guardado\": regla.get('timestamp', 'N/A'),\n",
        "                                       \"Num_Filas_Snapshot\": len(regla.get('datos_snapshot', []))})\n",
        "\n",
        "                    df_def = pd.DataFrame([{'termino_original': regla.get('termino_busqueda_original'), 'operador_principal_or': regla.get('operador_principal_or'),\n",
        "                                           'segmentos_parseados_json': json.dumps(regla.get('segmentos_parseados_para_and'), ensure_ascii=False, indent=2)}])\n",
        "                    df_def.to_excel(writer, sheet_name=f\"Def_{id_hoja}\"[:31], index=False)\n",
        "\n",
        "                    snap_list = regla.get('datos_snapshot')\n",
        "                    if snap_list:\n",
        "                        df_snap = pd.DataFrame(snap_list)\n",
        "                        if not df_snap.empty: df_snap.to_excel(writer, sheet_name=id_hoja, index=False)\n",
        "                if idx_export: pd.DataFrame(idx_export).to_excel(writer, sheet_name=\"Indice_Reglas_Exportadas\", index=False)\n",
        "            logging.info(f\"Exportación de {num_r} regla(s) completada a {ruta_save}\")\n",
        "            messagebox.showinfo(\"Éxito\", f\"{num_r} regla(s) exportadas a:\\n{ruta_save}\")\n",
        "            self._actualizar_estado(f\"Reglas exportadas a {Path(ruta_save).name}.\")\n",
        "            if messagebox.askyesno(\"Limpiar Reglas\", \"Exportación exitosa.\\n¿Limpiar reglas guardadas?\"):\n",
        "                self.reglas_guardadas.clear(); self._actualizar_estado(\"Reglas limpiadas.\")\n",
        "            self._actualizar_botones_estado_general()\n",
        "        except Exception as e:\n",
        "            logging.exception(\"Error exportando reglas.\"); messagebox.showerror(\"Error Exportar\", f\"No se pudo exportar:\\n{e}\")\n",
        "            self._actualizar_estado(\"Error exportando reglas.\")\n",
        "\n",
        "\n",
        "    def _sanitizar_nombre_archivo(self, texto: str, max_len: int = 50) -> str: # Utilidad, se mantiene\n",
        "        if not texto: return \"resultados\"\n",
        "        import re # Asegurar importación de re si se usa aquí explícitamente\n",
        "        sane = re.sub(r'[^\\w\\s-]', '', texto)\n",
        "        sane = re.sub(r'[-\\s]+', '_', sane).strip('_')\n",
        "        return sane[:max_len]\n",
        "\n",
        "    def _actualizar_estado_botones_operadores(self): # UI, se mantiene la lógica de habilitación\n",
        "        if self.motor.datos_diccionario is None and self.motor.datos_descripcion is None:\n",
        "            self._deshabilitar_botones_operadores(); return\n",
        "\n",
        "        texto = self.texto_busqueda_var.get()\n",
        "        for btn in self.op_buttons.values(): btn[\"state\"] = \"normal\"\n",
        "\n",
        "        cursor_pos = self.entrada_busqueda.index(tk.INSERT)\n",
        "        antes_cursor = texto[:cursor_pos].strip()\n",
        "        ultimo_char = antes_cursor[-1] if antes_cursor else \"\"\n",
        "\n",
        "        puede_logico = bool(antes_cursor) and ultimo_char not in ['+', '|', '/', '#','<','>','=','-',' ']\n",
        "        puede_nuevo_term = not antes_cursor or ultimo_char in ['+', '|', '/',' ']\n",
        "\n",
        "        self.op_buttons[\"+\"][\"state\"] = \"normal\" if puede_logico else \"disabled\"\n",
        "        self.op_buttons[\"|\"][\"state\"] = \"normal\" if puede_logico else \"disabled\"\n",
        "        self.op_buttons[\"#\"][\"state\"] = \"normal\" if puede_nuevo_term or antes_cursor.endswith(tuple(op+\" \" for op in [\"+\", \"|\", \"/\"])) else \"disabled\"\n",
        "\n",
        "        puede_comp_rango = puede_nuevo_term or (antes_cursor and not re.search(r'[<>=\\-]$', antes_cursor))\n",
        "        for op_k in [\">\", \"<\", \">=\", \"<=\", \"-\"]: # Asumiendo mapeo interno para '≥', '≤'\n",
        "             self.op_buttons[op_k][\"state\"] = \"normal\" if puede_comp_rango else \"disabled\"\n",
        "\n",
        "    def _insertar_operador_validado(self, operador: str): # UI, se mantiene\n",
        "        if self.motor.datos_diccionario is None and self.motor.datos_descripcion is None: return\n",
        "\n",
        "        txt_insert = operador\n",
        "        if operador in [\"+\", \"|\", \"/\"]:\n",
        "            prefijo = \" \" if not self.entrada_busqueda.get()[:self.entrada_busqueda.index(tk.INSERT)].endswith(\" \") else \"\"\n",
        "            txt_insert = f\"{prefijo}{operador} \"\n",
        "        elif operador == \"#\": txt_insert = f\"{operador}\"\n",
        "\n",
        "        self.entrada_busqueda.insert(tk.INSERT, txt_insert)\n",
        "        self.entrada_busqueda.focus_set()\n",
        "\n",
        "    def _deshabilitar_botones_operadores(self): # UI, se mantiene\n",
        "        for btn in self.op_buttons.values(): btn[\"state\"] = \"disabled\"\n",
        "\n",
        "    def on_closing(self): # UI, se mantiene\n",
        "        logger.info(\"Cerrando la aplicación...\")\n",
        "        self._guardar_configuracion()\n",
        "        self.destroy()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "9tJTTwg3c7yD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. `main.py` (Script Principal)"
      ],
      "metadata": {
        "id": "4t5RdtdPc7yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "import pandas as pd # Para la verificación de versión y dependencia\n",
        "import openpyxl # Para la verificación de versión y dependencia\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# Importar clases y configuraciones de los otros módulos\n",
        "from interfaz_grafica import InterfazGrafica\n",
        "from config import LOG_FILE_NAME # Usar la constante del archivo de configuración\n",
        "\n",
        "# Configuración del logging (similar a la original, pero centralizada aquí)\n",
        "logger = logging.getLogger() # Obtener el logger raíz\n",
        "logger.setLevel(logging.INFO) # Nivel por defecto, puede ser cambiado por config\n",
        "\n",
        "# Formatter\n",
        "formatter = logging.Formatter(\n",
        "    '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'\n",
        ")\n",
        "\n",
        "# File Handler\n",
        "try:\n",
        "    fh = logging.FileHandler(LOG_FILE_NAME, encoding='utf-8', mode='a')\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "except Exception as e:\n",
        "    print(f\"Error configurando FileHandler para logging: {e}\")\n",
        "    # No añadir handler si falla, para evitar problemas si no se puede escribir el log\n",
        "\n",
        "# Stream Handler (consola)\n",
        "sh = logging.StreamHandler()\n",
        "sh.setFormatter(formatter)\n",
        "logger.addHandler(sh)\n",
        "\n",
        "\n",
        "def verificar_dependencias():\n",
        "    \"\"\"Verifica si las dependencias críticas están instaladas.\"\"\"\n",
        "    missing_deps = []\n",
        "    try:\n",
        "        logger.info(f\"Pandas versión: {pd.__version__}\")\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"pandas\")\n",
        "        logger.critical(\"Dependencia faltante: pandas\")\n",
        "    except AttributeError: # pd puede ser importado pero __version__ no existir si es un mock o algo raro\n",
        "        missing_deps.append(\"pandas (versión desconocida)\")\n",
        "        logger.critical(\"No se pudo obtener la versión de pandas.\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        # openpyxl no siempre tiene __version__ fácilmente accesible a través de import openpyxl; openpyxl.__version__\n",
        "        # Es mejor solo comprobar la importación.\n",
        "        import openpyxl as op_xl # Renombrar para evitar conflicto con la variable global en otros módulos si existiera\n",
        "        logger.info(\"openpyxl importado correctamente.\")\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"openpyxl (para archivos .xlsx)\")\n",
        "        logger.warning(\"Dependencia opcional faltante: openpyxl. Funcionalidad para .xlsx limitada.\")\n",
        "\n",
        "    if \"pandas\" in missing_deps or \"pandas (versión desconocida)\" in missing_deps:\n",
        "        error_msg_dep = (\n",
        "            f\"Faltan librerías críticas: {', '.join(d for d in missing_deps if 'pandas' in d)}.\\n\"\n",
        "            f\"Instale con: pip install pandas\\n\"\n",
        "            f\"Otras dependencias opcionales faltantes: {', '.join(d for d in missing_deps if 'openpyxl' in d)}\"\n",
        "        )\n",
        "        logger.critical(error_msg_dep)\n",
        "        try:\n",
        "            root_temp = tk.Tk()\n",
        "            root_temp.withdraw()\n",
        "            messagebox.showerror(\"Dependencias Faltantes\", error_msg_dep)\n",
        "            root_temp.destroy()\n",
        "        except tk.TclError:\n",
        "            print(f\"ERROR CRÍTICO (Tkinter no disponible): {error_msg_dep}\")\n",
        "        except Exception as e_tk_init:\n",
        "            print(f\"ERROR CRÍTICO (Error al mostrar msgbox): {e_tk_init}\\n{error_msg_dep}\")\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logger.info(\"=============================================\")\n",
        "    logger.info(f\"=== Iniciando Aplicación Buscador ({Path(__file__).name}) ===\")\n",
        "\n",
        "    if not verificar_dependencias():\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        app = InterfazGrafica()\n",
        "        app.mainloop()\n",
        "    except Exception as main_error:\n",
        "        logger.critical(\"¡Error fatal no capturado en la aplicación!\", exc_info=True)\n",
        "        try:\n",
        "            root_err = tk.Tk()\n",
        "            root_err.withdraw()\n",
        "            messagebox.showerror(\"Error Fatal\", f\"Error crítico:\\n{main_error}\\nConsulte '{LOG_FILE_NAME}'.\")\n",
        "            root_err.destroy()\n",
        "        except Exception as fallback_error:\n",
        "            logger.error(f\"No se pudo mostrar el mensaje de error fatal vía Tkinter: {fallback_error}\")\n",
        "            print(f\"ERROR FATAL: {main_error}. Consulte {LOG_FILE_NAME}.\")\n",
        "    finally:\n",
        "        logger.info(f\"=== Finalizando Aplicación Buscador ({Path(__file__).name}) ===\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "HBiji2Wqc7yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cómo Usar Esta Estructura:**\n",
        "\n",
        "1.  Crea una carpeta para tu proyecto.\n",
        "2.  Dentro de esa carpeta, crea los seis archivos Python (`config.py`, `enums.py`, `utilidades.py`, `motor_busqueda.py`, `interfaz_grafica.py`, `main.py`) y copia el código correspondiente en cada uno.\n",
        "3.  Asegúrate de que todas las dependencias (`pandas`, `openpyxl`) estén instaladas en tu entorno Python.\n",
        "4.  Ejecuta el programa desde el archivo `main.py`: `python main.py`\n",
        "\n",
        "Esta organización te permitirá:\n",
        "\n",
        "* Tener cada parte del sistema con una responsabilidad clara.\n",
        "* Facilitar la modificación y prueba de componentes individuales.\n",
        "* Mejorar la legibilidad general del proyecto.\n",
        "* Gestionar las configuraciones de forma centralizada.\n",
        "\n",
        "Espero que esta estructura te sea de gran utilidad. ¡Avísame si tienes alguna otra pregunta!"
      ],
      "metadata": {
        "id": "8iuy4KATc7yF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
