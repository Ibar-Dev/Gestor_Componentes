{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibar-Dev/Gestor_Componentes/blob/main/Necesito_que_me_ayudes_a_organizar_el_c%C3%B3digo_que_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬°Claro que s√≠! Organizar el c√≥digo en clases bien definidas y un script principal es una excelente pr√°ctica para mejorar la mantenibilidad y la claridad de tu proyecto. üëç\n",
        "\n",
        "Aqu√≠ te presento la estructura que propongo y el c√≥digo para cada archivo:\n",
        "\n",
        "**Estructura de Archivos Sugerida:**\n",
        "\n",
        "1.  `config.py`: Para constantes y configuraciones (como `CONFIG_FILE` y `MAPEO_MAGNITUDES_PREDEFINIDO`).\n",
        "2.  `enums.py`: Para la enumeraci√≥n `OrigenResultados`.\n",
        "3.  `utilidades.py`: Para las clases `ExtractorMagnitud` y `ManejadorExcel`.\n",
        "4.  `motor_busqueda.py`: Para la clase `MotorBusqueda`.\n",
        "5.  `interfaz_grafica.py`: Para la clase `InterfazGrafica`.\n",
        "6.  `main.py`: El script principal que une todo.\n",
        "\n",
        "---\n",
        "## 1. `config.py`"
      ],
      "metadata": {
        "id": "LylFTMRQc7x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "from typing import Dict, List\n",
        "\n",
        "CONFIG_FILE_NAME = \"config_buscador_v0_7_1_mapeo.json\"\n",
        "LOG_FILE_NAME = \"buscador_app_v0_7_1_mapeo.log\"\n",
        "\n",
        "# Mapeo de magnitudes predefinido, movido aqu√≠ para centralizar configuraci√≥n.\n",
        "MAPEO_MAGNITUDES_PREDEFINIDO: Dict[str, List[str]] = {\n",
        "    \"AMPERIOS\": [\"A\", \"AMP\", \"AMPS\"],\n",
        "    \"VOLTIOS\": [\"V\", \"VA\", \"VAC\", \"VC\", \"VCC\", \"VCD\", \"VDC\"],\n",
        "    \"VATIOS\": [\"W\", \"WATTS\"],\n",
        "    \"GIGABIT\": [\"G\", \"GB\", \"GBE\", \"GE\", \"GBIT\"],\n",
        "    \"PUERTO\": [\"P\", \"PORT\", \"PORTS\", \"PTOS\"],\n",
        "    \"HERTZ\": [\"HZ\", \"KHZ\", \"MHZ\", \"GHZ\"],\n",
        "    \"AH\": [], \"ANTENNA\": [], \"BASE\": [], \"BIT\": [], \"ETH\": [], \"FE\": [],\n",
        "    \"GBASE\": [], \"GBASEWAN\": [], \"GBIC\": [], \"GBPS\": [], \"GH\": [], \"KM\": [],\n",
        "    \"KVA\": [], \"KW\": [], \"LINEAS\": [], \"LINES\": [], \"NM\": [], \"E\": [],\n",
        "    \"POTS\": [], \"STM\": []\n",
        "}\n",
        "\n",
        "# Otros valores de configuraci√≥n que puedan ser necesarios\n",
        "# Ejemplo:\n",
        "# DEFAULT_WINDOW_GEOMETRY = \"1250x800\"\n",
        "# DEFAULT_LOG_LEVEL = \"INFO\" # o logging.INFO si se importa logging aqu√≠"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "_qjPvDxec7x_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. `enums.py`"
      ],
      "metadata": {
        "id": "VYSJdc65c7yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enums.py\n",
        "from enum import Enum, auto\n",
        "\n",
        "class OrigenResultados(Enum):\n",
        "    NINGUNO = 0\n",
        "    VIA_DICCIONARIO_CON_RESULTADOS_DESC = auto()\n",
        "    VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS = auto()\n",
        "    VIA_DICCIONARIO_SIN_RESULTADOS_DESC = auto()\n",
        "    DIRECTO_DESCRIPCION_CON_RESULTADOS = auto()\n",
        "    DIRECTO_DESCRIPCION_VACIA = auto()\n",
        "    ERROR_CARGA_DICCIONARIO = auto()\n",
        "    ERROR_CARGA_DESCRIPCION = auto()\n",
        "    ERROR_CONFIGURACION_COLUMNAS_DICC = auto()\n",
        "    ERROR_CONFIGURACION_COLUMNAS_DESC = auto()\n",
        "    ERROR_BUSQUEDA_INTERNA_MOTOR = auto()\n",
        "    TERMINO_INVALIDO = auto()\n",
        "\n",
        "    @property\n",
        "    def es_via_diccionario(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC,\n",
        "            OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS,\n",
        "            OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_directo_descripcion(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.DIRECTO_DESCRIPCION_CON_RESULTADOS,\n",
        "            OrigenResultados.DIRECTO_DESCRIPCION_VACIA,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_error_carga(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.ERROR_CARGA_DICCIONARIO,\n",
        "            OrigenResultados.ERROR_CARGA_DESCRIPCION,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_error_configuracion(self) -> bool:\n",
        "        return self in {\n",
        "            OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DICC,\n",
        "            OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DESC,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def es_error_operacional(self) -> bool:\n",
        "        return self == OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR\n",
        "\n",
        "    @property\n",
        "    def es_termino_invalido(self) -> bool:\n",
        "        return self == OrigenResultados.TERMINO_INVALIDO"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "n5gB1u2jc7yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. `utilidades.py`"
      ],
      "metadata": {
        "id": "gAjXc9Eoc7yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utilidades.py\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "\n",
        "# Importar configuraci√≥n\n",
        "from config import MAPEO_MAGNITUDES_PREDEFINIDO\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ExtractorMagnitud:\n",
        "    def __init__(self, mapeo_magnitudes: Optional[Dict[str, List[str]]] = None):\n",
        "        self.sinonimo_a_canonico_normalizado: Dict[str, str] = {}\n",
        "        # Usar el mapeo de config.py si no se proporciona uno espec√≠fico\n",
        "        mapeo_a_usar = mapeo_magnitudes if mapeo_magnitudes is not None else MAPEO_MAGNITUDES_PREDEFINIDO\n",
        "\n",
        "        for forma_canonica, lista_sinonimos in mapeo_a_usar.items():\n",
        "            canonico_norm = self._normalizar_texto(forma_canonica)\n",
        "            if not canonico_norm:\n",
        "                logger.warning(f\"Forma can√≥nica '{forma_canonica}' result√≥ vac√≠a tras normalizar. Se ignora.\")\n",
        "                continue\n",
        "\n",
        "            self.sinonimo_a_canonico_normalizado[canonico_norm] = canonico_norm\n",
        "\n",
        "            for sinonimo in lista_sinonimos:\n",
        "                sinonimo_norm = self._normalizar_texto(sinonimo)\n",
        "                if sinonimo_norm:\n",
        "                    if sinonimo_norm in self.sinonimo_a_canonico_normalizado and \\\n",
        "                       self.sinonimo_a_canonico_normalizado[sinonimo_norm] != canonico_norm:\n",
        "                        logger.warning(\n",
        "                            f\"Conflicto de mapeo: El sin√≥nimo normalizado '{sinonimo_norm}' (de '{sinonimo}' para '{forma_canonica}') \"\n",
        "                            f\"ya est√° mapeado a '{self.sinonimo_a_canonico_normalizado[sinonimo_norm]}'. \"\n",
        "                            f\"Se sobrescribir√° con el mapeo a '{canonico_norm}'. \"\n",
        "                            \"Revise su MAPEO_MAGNITUDES_PREDEFINIDO para evitar ambig√ºedades.\"\n",
        "                        )\n",
        "                    self.sinonimo_a_canonico_normalizado[sinonimo_norm] = canonico_norm\n",
        "        logger.debug(f\"ExtractorMagnitud inicializado con mapeo: {self.sinonimo_a_canonico_normalizado}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalizar_texto(texto: str) -> str:\n",
        "        if not isinstance(texto, str) or not texto:\n",
        "            return \"\"\n",
        "        try:\n",
        "            texto_upper = texto.upper()\n",
        "            forma_normalizada = unicodedata.normalize(\"NFKD\", texto_upper)\n",
        "            return \"\".join(c for c in forma_normalizada if not unicodedata.combining(c))\n",
        "        except TypeError:\n",
        "            return \"\"\n",
        "\n",
        "    def obtener_magnitud_normalizada(self, texto_unidad: str) -> Optional[str]:\n",
        "        if not texto_unidad:\n",
        "            return None\n",
        "        normalizada = self._normalizar_texto(texto_unidad)\n",
        "        if not normalizada:\n",
        "            return None\n",
        "        return self.sinonimo_a_canonico_normalizado.get(normalizada)\n",
        "\n",
        "\n",
        "class ManejadorExcel:\n",
        "    @staticmethod\n",
        "    def cargar_excel(\n",
        "        ruta_archivo: Union[str, Path],\n",
        "    ) -> Tuple[Optional[pd.DataFrame], Optional[str]]:\n",
        "        ruta = Path(ruta_archivo)\n",
        "        logger.info(f\"Intentando cargar archivo Excel: {ruta}\")\n",
        "        if not ruta.exists():\n",
        "            error_msg = f\"¬°Archivo no encontrado! Ruta: {ruta}\"\n",
        "            logger.error(error_msg)\n",
        "            return None, error_msg\n",
        "        try:\n",
        "            engine = \"openpyxl\" if ruta.suffix.lower() == \".xlsx\" else None\n",
        "            df = pd.read_excel(ruta, engine=engine)\n",
        "            logger.info(f\"Archivo '{ruta.name}' cargado ({len(df)} filas).\")\n",
        "            return df, None\n",
        "        except Exception as e:\n",
        "            error_msg = (\n",
        "                f\"No se pudo cargar el archivo:\\n{ruta}\\n\\nError: {e}\\n\\n\"\n",
        "                \"Posibles causas:\\n\"\n",
        "                \"- El archivo est√° siendo usado por otro programa.\\n\"\n",
        "                \"- No tiene instalado 'openpyxl' para .xlsx (o 'xlrd' para .xls).\\n\"\n",
        "                \"- El archivo est√° corrupto o en formato no soportado.\"\n",
        "            )\n",
        "            logger.exception(f\"Error inesperado al cargar archivo Excel: {ruta}\")\n",
        "            return None, error_msg"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "huNo7B91c7yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. `motor_busqueda.py`"
      ],
      "metadata": {
        "id": "rpCrW7m4c7yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# motor_busqueda.py\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Optional, List, Tuple, Dict, Any, Set, Union\n",
        "\n",
        "from enums import OrigenResultados\n",
        "from utilidades import ExtractorMagnitud, ManejadorExcel\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class MotorBusqueda:\n",
        "    def __init__(self, indices_diccionario_cfg: Optional[List[int]] = None):\n",
        "        self.datos_diccionario: Optional[pd.DataFrame] = None\n",
        "        self.datos_descripcion: Optional[pd.DataFrame] = None\n",
        "        self.archivo_diccionario_actual: Optional[Path] = None\n",
        "        self.archivo_descripcion_actual: Optional[Path] = None\n",
        "\n",
        "        self.indices_columnas_busqueda_dic: List[int] = (\n",
        "            indices_diccionario_cfg if isinstance(indices_diccionario_cfg, list) else []\n",
        "        )\n",
        "        logger.info(\n",
        "            f\"MotorBusqueda inicializado. √çndices b√∫squeda diccionario: {self.indices_columnas_busqueda_dic or 'Todas las de texto'}\"\n",
        "        )\n",
        "\n",
        "        self.patron_comparacion = re.compile(\n",
        "            r\"^([<>]=?)(\\d+(?:[.,]\\d+)?)\\s*([a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë¬µŒ©]+)?(.*)$\"\n",
        "        )\n",
        "        self.patron_rango = re.compile(\n",
        "            r\"^(\\d+(?:[.,]\\d+)?)\\s*-\\s*(\\d+(?:[.,]\\d+)?)\\s*([a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë¬µŒ©]+)?$\"\n",
        "        )\n",
        "        self.patron_negacion = re.compile(r\"^#(.+)$\")\n",
        "        self.patron_num_unidad_df = re.compile(\n",
        "            r\"(\\d+(?:[.,]\\d+)?)\\s*([a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë¬µŒ©]+)?\"\n",
        "        )\n",
        "        self.extractor_magnitud = ExtractorMagnitud() # Usa el mapeo por defecto de config.py\n",
        "\n",
        "    def cargar_excel_diccionario(self, ruta_str: str) -> Tuple[bool, Optional[str]]:\n",
        "        ruta = Path(ruta_str)\n",
        "        df_cargado, error_msg_carga = ManejadorExcel.cargar_excel(ruta)\n",
        "\n",
        "        if df_cargado is None:\n",
        "            self.datos_diccionario = None\n",
        "            self.archivo_diccionario_actual = None\n",
        "            return False, error_msg_carga or \"Error desconocido al cargar diccionario.\"\n",
        "\n",
        "        valido, msg_val_cols = self._validar_columnas_df(\n",
        "            df_cargado, self.indices_columnas_busqueda_dic, \"diccionario\"\n",
        "        )\n",
        "        if not valido:\n",
        "            logger.warning(\n",
        "                f\"Validaci√≥n de columnas del diccionario fallida. Carga invalidada. Causa: {msg_val_cols}\"\n",
        "            )\n",
        "            return False, msg_val_cols or \"Validaci√≥n de columnas del diccionario fallida.\"\n",
        "\n",
        "        self.datos_diccionario = df_cargado\n",
        "        self.archivo_diccionario_actual = ruta\n",
        "        return True, None\n",
        "\n",
        "    def cargar_excel_descripcion(self, ruta_str: str) -> Tuple[bool, Optional[str]]:\n",
        "        ruta = Path(ruta_str)\n",
        "        df_cargado, error_msg_carga = ManejadorExcel.cargar_excel(ruta)\n",
        "\n",
        "        if df_cargado is None:\n",
        "            self.datos_descripcion = None\n",
        "            self.archivo_descripcion_actual = None\n",
        "            return False, error_msg_carga or \"Error desconocido al cargar descripciones.\"\n",
        "\n",
        "        self.datos_descripcion = df_cargado\n",
        "        self.archivo_descripcion_actual = ruta\n",
        "        return True, None\n",
        "\n",
        "    def _validar_columnas_df(\n",
        "        self, df: Optional[pd.DataFrame], indices_cfg: List[int], nombre_df_log: str\n",
        "    ) -> Tuple[bool, Optional[str]]:\n",
        "        if df is None:\n",
        "            msg = f\"DataFrame '{nombre_df_log}' es None, no se puede validar.\"\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "\n",
        "        num_cols_df = len(df.columns)\n",
        "\n",
        "        if not indices_cfg or indices_cfg == [-1]:\n",
        "            if num_cols_df == 0:\n",
        "                msg = f\"El archivo del {nombre_df_log} est√° vac√≠o o no contiene columnas (modo 'todas').\"\n",
        "                logger.error(msg)\n",
        "                return False, msg\n",
        "            return True, None\n",
        "\n",
        "        if not all(isinstance(idx, int) and idx >= 0 for idx in indices_cfg):\n",
        "            msg = f\"Configuraci√≥n de √≠ndices para {nombre_df_log} inv√°lida: {indices_cfg}. Deben ser enteros no negativos.\"\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "\n",
        "        max_indice_requerido = max(indices_cfg) if indices_cfg else -1\n",
        "\n",
        "        if num_cols_df == 0:\n",
        "            msg = f\"El {nombre_df_log} no tiene columnas.\"\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "        elif max_indice_requerido >= num_cols_df:\n",
        "            msg = (\n",
        "                f\"El {nombre_df_log} necesita al menos {max_indice_requerido + 1} columnas \"\n",
        "                f\"para los √≠ndices configurados ({indices_cfg}), pero solo tiene {num_cols_df}.\"\n",
        "            )\n",
        "            logger.error(msg)\n",
        "            return False, msg\n",
        "        return True, None\n",
        "\n",
        "    def _obtener_nombres_columnas_busqueda_df(\n",
        "        self, df: Optional[pd.DataFrame], indices_cfg: List[int], nombre_df_log: str\n",
        "    ) -> Tuple[Optional[List[str]], Optional[str]]:\n",
        "        if df is None:\n",
        "            msg = f\"Intentando obtener nombres de columnas de un DataFrame ({nombre_df_log}) que es None.\"\n",
        "            logger.error(msg)\n",
        "            return None, msg\n",
        "\n",
        "        columnas_disponibles = df.columns\n",
        "        num_cols_df = len(columnas_disponibles)\n",
        "\n",
        "        if not indices_cfg or indices_cfg == [-1]:\n",
        "            cols_texto_obj = [\n",
        "                col for col in df.columns\n",
        "                if pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col])\n",
        "            ]\n",
        "            if cols_texto_obj:\n",
        "                logger.info(\n",
        "                    f\"Buscando en columnas de texto/object (detectadas) del {nombre_df_log}: {cols_texto_obj}\"\n",
        "                )\n",
        "                return cols_texto_obj, None\n",
        "            elif num_cols_df > 0:\n",
        "                logger.warning(\n",
        "                    f\"No se encontraron columnas de texto/object en {nombre_df_log}. Se usar√°n todas las {num_cols_df} columnas.\"\n",
        "                )\n",
        "                return list(df.columns), None\n",
        "            else:\n",
        "                msg = f\"El DataFrame del {nombre_df_log} no tiene columnas.\"\n",
        "                logger.error(msg)\n",
        "                return None, msg\n",
        "\n",
        "        nombres_columnas_seleccionadas = []\n",
        "        indices_validos_usados = []\n",
        "        for indice in indices_cfg:\n",
        "            if 0 <= indice < num_cols_df:\n",
        "                nombres_columnas_seleccionadas.append(columnas_disponibles[indice])\n",
        "                indices_validos_usados.append(indice)\n",
        "            else:\n",
        "                logger.warning(\n",
        "                    f\"√çndice {indice} para {nombre_df_log} es inv√°lido o fuera de rango (0 a {num_cols_df-1}). Ignorado.\"\n",
        "                )\n",
        "\n",
        "        if not nombres_columnas_seleccionadas:\n",
        "            msg = f\"No se encontraron columnas v√°lidas en {nombre_df_log} con los √≠ndices configurados: {indices_cfg}\"\n",
        "            logger.error(msg)\n",
        "            return None, msg\n",
        "\n",
        "        logger.debug(\n",
        "            f\"Se buscar√° en columnas del {nombre_df_log}: {nombres_columnas_seleccionadas} (√≠ndices: {indices_validos_usados})\"\n",
        "        )\n",
        "        return nombres_columnas_seleccionadas, None\n",
        "\n",
        "    def _parsear_nivel1_or(self, texto_complejo: str) -> Tuple[str, List[str]]:\n",
        "        texto_limpio = texto_complejo.strip()\n",
        "        if not texto_limpio:\n",
        "            return 'OR', []\n",
        "\n",
        "        if '|' in texto_limpio:\n",
        "            segmentos = [s.strip() for s in re.split(r'\\s*\\|\\s*', texto_limpio) if s.strip()]\n",
        "            return 'OR', segmentos\n",
        "        elif '/' in texto_limpio:\n",
        "            segmentos = [s.strip() for s in re.split(r'\\s*/\\s*', texto_limpio) if s.strip()]\n",
        "            return 'OR', segmentos\n",
        "        else:\n",
        "            return 'AND', [texto_limpio]\n",
        "\n",
        "    def _parsear_nivel2_and(self, termino_segmento_n1: str) -> Tuple[str, List[str]]:\n",
        "        termino_limpio = termino_segmento_n1.strip()\n",
        "        if not termino_limpio:\n",
        "            return 'AND', []\n",
        "\n",
        "        op_principal_interno = 'AND'\n",
        "        separador_interno = None\n",
        "\n",
        "        if '+' in termino_limpio:\n",
        "            separador_interno = '+'\n",
        "\n",
        "        terminos_brutos_finales = []\n",
        "        if separador_interno:\n",
        "            estado = 0\n",
        "            termino_actual_maquina = []\n",
        "            pos = 0\n",
        "            while pos < len(termino_limpio):\n",
        "                char = termino_limpio[pos]\n",
        "                if estado == 0:\n",
        "                    if char == separador_interno:\n",
        "                        sub_termino = \"\".join(termino_actual_maquina).strip()\n",
        "                        if sub_termino: terminos_brutos_finales.append(sub_termino)\n",
        "                        termino_actual_maquina = []\n",
        "                    elif char in \"<>=\":\n",
        "                        estado = 1\n",
        "                        termino_actual_maquina.append(char)\n",
        "                    elif char.isdigit():\n",
        "                        estado = 2\n",
        "                        termino_actual_maquina.append(char)\n",
        "                    else:\n",
        "                        termino_actual_maquina.append(char)\n",
        "                elif estado == 1:\n",
        "                    termino_actual_maquina.append(char)\n",
        "                    if char.isdigit() or char == \".\":\n",
        "                        estado = 2\n",
        "                    elif char.isspace() and not any(c in \"<>=\" for c in termino_actual_maquina[-2:]):\n",
        "                        if \"\".join(termino_actual_maquina).strip() in ['<','>','<=','>=','=']:\n",
        "                           pass\n",
        "                        else:\n",
        "                           estado = 0\n",
        "                    elif not (char in \"<>=\" or char.isalnum() or char in ['.',',','-']):\n",
        "                        estado = 0\n",
        "                elif estado == 2:\n",
        "                    termino_actual_maquina.append(char)\n",
        "                    if not (char.isdigit() or char in ['.', ',']):\n",
        "                        if char.isalpha():\n",
        "                            estado = 3\n",
        "                        else:\n",
        "                            estado = 0\n",
        "                elif estado == 3:\n",
        "                    termino_actual_maquina.append(char)\n",
        "                    if not char.isalnum():\n",
        "                        estado = 0\n",
        "                pos += 1\n",
        "\n",
        "            sub_termino_final = \"\".join(termino_actual_maquina).strip()\n",
        "            if sub_termino_final: terminos_brutos_finales.append(sub_termino_final)\n",
        "\n",
        "            if not terminos_brutos_finales and termino_limpio == separador_interno:\n",
        "                return op_principal_interno, []\n",
        "        else:\n",
        "            terminos_brutos_finales = [termino_limpio]\n",
        "\n",
        "        return op_principal_interno, [t for t in terminos_brutos_finales if t]\n",
        "\n",
        "    def _analizar_terminos(self, terminos_brutos: List[str]) -> List[Dict[str, Any]]:\n",
        "        palabras_analizadas = []\n",
        "        for term_orig_bruto in terminos_brutos:\n",
        "            term_orig = str(term_orig_bruto)\n",
        "            term = term_orig.strip()\n",
        "            if not term: continue\n",
        "\n",
        "            item_analizado: Dict[str, Any] = {'original': term_orig, 'negate': False}\n",
        "            match_neg = self.patron_negacion.match(term)\n",
        "            if match_neg:\n",
        "                item_analizado['negate'] = True\n",
        "                term = match_neg.group(1).strip()\n",
        "                if not term: continue\n",
        "\n",
        "            match_comp = self.patron_comparacion.match(term)\n",
        "            match_range = self.patron_rango.match(term)\n",
        "\n",
        "            if match_comp:\n",
        "                op, v_str, unidad_str, _ = match_comp.groups()\n",
        "                v_num = self._parse_numero(v_str)\n",
        "                if v_num is not None:\n",
        "                    op_map = {'>': 'gt', '<': 'lt', '>=': 'ge', '<=': 'le', '=': 'eq'}\n",
        "                    unidad_canon_comp = None\n",
        "                    if unidad_str:\n",
        "                        unidad_canon_comp = self.extractor_magnitud.obtener_magnitud_normalizada(unidad_str.strip())\n",
        "                        if unidad_canon_comp is None:\n",
        "                            logger.warning(\n",
        "                                f\"Unidad de b√∫squeda '{unidad_str.strip()}' en '{term}' no reconocida. \"\n",
        "                                \"Comparaci√≥n num√©rica sin filtro de unidad.\"\n",
        "                            )\n",
        "                    item_analizado.update({\n",
        "                        'tipo': op_map.get(op, 'str'),\n",
        "                        'valor': v_num,\n",
        "                        'unidad_busqueda': unidad_canon_comp\n",
        "                    })\n",
        "                else:\n",
        "                    item_analizado.update({'tipo': 'str', 'valor': self.extractor_magnitud._normalizar_texto(term)})\n",
        "            elif match_range:\n",
        "                v1_str, v2_str, unidad_rango_str = match_range.groups()\n",
        "                v1, v2 = self._parse_numero(v1_str), self._parse_numero(v2_str)\n",
        "                if v1 is not None and v2 is not None:\n",
        "                    unidad_canon_range = None\n",
        "                    if unidad_rango_str:\n",
        "                        unidad_canon_range = self.extractor_magnitud.obtener_magnitud_normalizada(unidad_rango_str.strip())\n",
        "                        if unidad_canon_range is None:\n",
        "                            logger.warning(\n",
        "                                f\"Unidad de rango '{unidad_rango_str.strip()}' en '{term}' no reconocida. \"\n",
        "                                \"Rango sin filtro de unidad.\"\n",
        "                            )\n",
        "                    item_analizado.update({\n",
        "                        'tipo': 'range',\n",
        "                        'valor': sorted([v1, v2]),\n",
        "                        'unidad_busqueda': unidad_canon_range\n",
        "                    })\n",
        "                else:\n",
        "                    item_analizado.update({'tipo': 'str', 'valor': self.extractor_magnitud._normalizar_texto(term)})\n",
        "            else:\n",
        "                item_analizado.update({'tipo': 'str', 'valor': self.extractor_magnitud._normalizar_texto(term)})\n",
        "            palabras_analizadas.append(item_analizado)\n",
        "        logger.debug(f\"T√©rminos analizados (motor): {palabras_analizadas}\")\n",
        "        return palabras_analizadas\n",
        "\n",
        "    def _parse_numero(self, num_str: Any) -> Optional[float]:\n",
        "        if not isinstance(num_str, (str, int, float)): return None\n",
        "        try:\n",
        "            return float(str(num_str).replace(',', '.'))\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "    def _generar_mascara_para_un_termino(self, df: pd.DataFrame, cols_a_buscar: List[str], termino_analizado: Dict[str, Any]) -> pd.Series:\n",
        "        mascara_total_subtermino = pd.Series(False, index=df.index)\n",
        "        tipo_sub = termino_analizado['tipo']\n",
        "        valor_sub = termino_analizado['valor']\n",
        "        unidad_sub_requerida_canon = termino_analizado.get('unidad_busqueda')\n",
        "        es_negado = termino_analizado.get('negate', False)\n",
        "\n",
        "        for col_nombre in cols_a_buscar:\n",
        "            if col_nombre not in df.columns:\n",
        "                logger.warning(f\"Columna '{col_nombre}' no encontrada en DF. Saltando.\")\n",
        "                continue\n",
        "            col_series = df[col_nombre]\n",
        "            mascara_col_actual = pd.Series(False, index=df.index)\n",
        "\n",
        "            if tipo_sub in ['gt', 'lt', 'ge', 'le', 'range', 'eq']:\n",
        "                for idx, valor_celda in col_series.items():\n",
        "                    if pd.isna(valor_celda) or str(valor_celda).strip() == \"\": continue\n",
        "\n",
        "                    for match_celda in self.patron_num_unidad_df.finditer(str(valor_celda)):\n",
        "                        try:\n",
        "                            num_celda_val = float(match_celda.group(1).replace(',', '.'))\n",
        "                            unidad_celda_canon: Optional[str] = None\n",
        "                            if match_celda.group(2):\n",
        "                                unidad_celda_canon = self.extractor_magnitud.obtener_magnitud_normalizada(match_celda.group(2))\n",
        "\n",
        "                            unidad_coincide = False\n",
        "                            if unidad_sub_requerida_canon is None:\n",
        "                                unidad_coincide = True\n",
        "                            elif unidad_celda_canon is not None and unidad_celda_canon == unidad_sub_requerida_canon:\n",
        "                                unidad_coincide = True\n",
        "\n",
        "                            if not unidad_coincide:\n",
        "                                continue\n",
        "\n",
        "                            cond_ok = False\n",
        "                            if tipo_sub == 'eq' and num_celda_val == valor_sub : cond_ok = True\n",
        "                            elif tipo_sub == 'gt' and num_celda_val > valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'lt' and num_celda_val < valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'ge' and num_celda_val >= valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'le' and num_celda_val <= valor_sub: cond_ok = True\n",
        "                            elif tipo_sub == 'range' and valor_sub[0] <= num_celda_val <= valor_sub[1]: cond_ok = True\n",
        "\n",
        "                            if cond_ok:\n",
        "                                mascara_col_actual.at[idx] = True\n",
        "                                break\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "                    if mascara_col_actual.at[idx]: continue\n",
        "\n",
        "            elif tipo_sub == 'str':\n",
        "                termino_regex_escapado = r\"\\b\" + re.escape(str(valor_sub)) + r\"\\b\"\n",
        "                try:\n",
        "                    serie_normalizada = col_series.astype(str).map(self.extractor_magnitud._normalizar_texto)\n",
        "                    mascara_col_actual = serie_normalizada.str.contains(termino_regex_escapado, regex=True, na=False)\n",
        "                except Exception as e_conv_str:\n",
        "                    logger.warning(f\"No se pudo convertir/buscar string en columna '{col_nombre}': {e_conv_str}\")\n",
        "\n",
        "            mascara_total_subtermino |= mascara_col_actual.fillna(False)\n",
        "\n",
        "        return ~mascara_total_subtermino if es_negado else mascara_total_subtermino\n",
        "\n",
        "    def _aplicar_mascara_combinada_para_segmento_and(\n",
        "        self, df: pd.DataFrame, cols_a_buscar: List[str], terminos_analizados_segmento: List[Dict[str, Any]]\n",
        "    ) -> pd.Series:\n",
        "        if df is None or df.empty or not cols_a_buscar:\n",
        "            return pd.Series(False, index=df.index if df is not None else None)\n",
        "\n",
        "        if not terminos_analizados_segmento:\n",
        "            return pd.Series(False, index=df.index)\n",
        "\n",
        "        mascara_final_segmento_and = pd.Series(True, index=df.index)\n",
        "\n",
        "        for termino_individual_analizado in terminos_analizados_segmento:\n",
        "            mascara_este_termino = self._generar_mascara_para_un_termino(df, cols_a_buscar, termino_individual_analizado)\n",
        "            mascara_final_segmento_and &= mascara_este_termino\n",
        "\n",
        "        return mascara_final_segmento_and\n",
        "\n",
        "    def _combinar_mascaras_de_segmentos_or(self, lista_mascaras_segmentos: List[pd.Series], df_index_ref: pd.Index) -> pd.Series:\n",
        "        if not lista_mascaras_segmentos:\n",
        "            return pd.Series(False, index=df_index_ref)\n",
        "\n",
        "        mascara_final_or = pd.Series(False, index=lista_mascaras_segmentos[0].index)\n",
        "        for mascara_segmento in lista_mascaras_segmentos:\n",
        "            mascara_final_or |= mascara_segmento\n",
        "        return mascara_final_or\n",
        "\n",
        "    def _procesar_busqueda_en_df_objetivo(\n",
        "        self,\n",
        "        df_objetivo: pd.DataFrame,\n",
        "        cols_objetivo: List[str],\n",
        "        termino_busqueda_original: str\n",
        "    ) -> Tuple[pd.DataFrame, Optional[str]]:\n",
        "\n",
        "        if not termino_busqueda_original.strip():\n",
        "            return df_objetivo.copy(), None\n",
        "\n",
        "        op_nivel1, segmentos_nivel1 = self._parsear_nivel1_or(termino_busqueda_original)\n",
        "\n",
        "        if not segmentos_nivel1:\n",
        "            return pd.DataFrame(columns=df_objetivo.columns), \"T√©rmino de b√∫squeda inv√°lido o vac√≠o tras parseo OR.\"\n",
        "\n",
        "        lista_mascaras_para_or = []\n",
        "        for seg_n1 in segmentos_nivel1:\n",
        "            op_nivel2, terminos_brutos_n2 = self._parsear_nivel2_and(seg_n1)\n",
        "\n",
        "            terminos_atomicos_analizados = self._analizar_terminos(terminos_brutos_n2)\n",
        "\n",
        "            if not terminos_atomicos_analizados:\n",
        "                logger.warning(f\"Segmento OR '{seg_n1}' no produjo t√©rminos analizables. No contribuir√°.\")\n",
        "                mascara_segmento_n1 = pd.Series(False, index=df_objetivo.index)\n",
        "            else:\n",
        "                mascara_segmento_n1 = self._aplicar_mascara_combinada_para_segmento_and(\n",
        "                    df_objetivo, cols_objetivo, terminos_atomicos_analizados\n",
        "                )\n",
        "            lista_mascaras_para_or.append(mascara_segmento_n1)\n",
        "\n",
        "        if not lista_mascaras_para_or:\n",
        "             return pd.DataFrame(columns=df_objetivo.columns), \"Ning√∫n segmento de b√∫squeda produjo resultados.\"\n",
        "\n",
        "        mascara_final_df_objetivo = self._combinar_mascaras_de_segmentos_or(lista_mascaras_para_or, df_objetivo.index)\n",
        "        return df_objetivo[mascara_final_df_objetivo].copy(), None\n",
        "\n",
        "    def buscar(\n",
        "        self,\n",
        "        termino_busqueda_original: str,\n",
        "        buscar_via_diccionario_flag: bool,\n",
        "    ) -> Tuple[Optional[pd.DataFrame], OrigenResultados, Optional[pd.DataFrame], Optional[str]]:\n",
        "        logger.info(\n",
        "            f\"Motor.buscar: termino='{termino_busqueda_original}', via_dicc={buscar_via_diccionario_flag}\"\n",
        "        )\n",
        "\n",
        "        fcds_obtenidos: Optional[pd.DataFrame] = None\n",
        "        df_vacio_desc = pd.DataFrame(columns=self.datos_descripcion.columns if self.datos_descripcion is not None else [])\n",
        "\n",
        "        if not termino_busqueda_original.strip():\n",
        "            if self.datos_descripcion is not None:\n",
        "                return self.datos_descripcion.copy(), OrigenResultados.DIRECTO_DESCRIPCION_VACIA, None, None\n",
        "            return df_vacio_desc, OrigenResultados.ERROR_CARGA_DESCRIPCION, None, \"Descripciones no cargadas.\"\n",
        "\n",
        "        if buscar_via_diccionario_flag:\n",
        "            if self.datos_diccionario is None:\n",
        "                return None, OrigenResultados.ERROR_CARGA_DICCIONARIO, None, \"Diccionario no cargado.\"\n",
        "\n",
        "            cols_dic, err_cols_dic = self._obtener_nombres_columnas_busqueda_df(\n",
        "                self.datos_diccionario, self.indices_columnas_busqueda_dic, \"diccionario (b√∫squeda)\"\n",
        "            )\n",
        "            if not cols_dic:\n",
        "                return None, OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DICC, None, err_cols_dic\n",
        "\n",
        "            try:\n",
        "                fcds_obtenidos, err_proc_dic = self._procesar_busqueda_en_df_objetivo(\n",
        "                    self.datos_diccionario, cols_dic, termino_busqueda_original\n",
        "                )\n",
        "                if err_proc_dic:\n",
        "                     return None, OrigenResultados.TERMINO_INVALIDO, None, err_proc_dic\n",
        "                logger.info(f\"FCDs: {len(fcds_obtenidos) if fcds_obtenidos is not None else 0}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(\"Error buscando en diccionario.\")\n",
        "                return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, None, f\"Error interno (dic): {e}\"\n",
        "\n",
        "            if self.datos_descripcion is None:\n",
        "                return None, OrigenResultados.ERROR_CARGA_DESCRIPCION, fcds_obtenidos, \"Descripciones no cargadas.\"\n",
        "\n",
        "            if fcds_obtenidos is None or fcds_obtenidos.empty:\n",
        "                return df_vacio_desc, OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC, fcds_obtenidos, None\n",
        "\n",
        "            terms_fcd = self._extraer_terminos_diccionario(fcds_obtenidos, cols_dic)\n",
        "            if not terms_fcd:\n",
        "                return df_vacio_desc, OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS, fcds_obtenidos, None\n",
        "\n",
        "            try:\n",
        "                term_or_desc = \" | \".join(terms_fcd)\n",
        "                cols_desc_fcd, err_cols_desc_fcd = self._obtener_nombres_columnas_busqueda_df(\n",
        "                     self.datos_descripcion, [], \"descripciones (v√≠a FCDs)\"\n",
        "                )\n",
        "                if not cols_desc_fcd:\n",
        "                    return None, OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DESC, fcds_obtenidos, err_cols_desc_fcd\n",
        "\n",
        "                res_desc_via_dic, err_proc_desc_fcd = self._procesar_busqueda_en_df_objetivo(\n",
        "                    self.datos_descripcion, cols_desc_fcd, term_or_desc\n",
        "                )\n",
        "                if err_proc_desc_fcd:\n",
        "                    return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, fcds_obtenidos, f\"Error (desc v√≠a FCD): {err_proc_desc_fcd}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(\"Error buscando t√©rminos de FCDs en descripciones.\")\n",
        "                return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, fcds_obtenidos, f\"Error interno (desc v√≠a FCD): {e}\"\n",
        "\n",
        "            if res_desc_via_dic is None or res_desc_via_dic.empty:\n",
        "                return df_vacio_desc, OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC, fcds_obtenidos, None\n",
        "            return res_desc_via_dic, OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC, fcds_obtenidos, None\n",
        "\n",
        "        else: # B√∫squeda directa\n",
        "            if self.datos_descripcion is None:\n",
        "                return None, OrigenResultados.ERROR_CARGA_DESCRIPCION, None, \"Descripciones no cargadas.\"\n",
        "\n",
        "            cols_desc_directo, err_cols_desc_directo = self._obtener_nombres_columnas_busqueda_df(\n",
        "                self.datos_descripcion, [], \"descripciones (directa)\"\n",
        "            )\n",
        "            if not cols_desc_directo:\n",
        "                return None, OrigenResultados.ERROR_CONFIGURACION_COLUMNAS_DESC, None, err_cols_desc_directo\n",
        "\n",
        "            try:\n",
        "                res_directos, err_proc_desc_directo = self._procesar_busqueda_en_df_objetivo(\n",
        "                    self.datos_descripcion, cols_desc_directo, termino_busqueda_original\n",
        "                )\n",
        "                if err_proc_desc_directo:\n",
        "                    return None, OrigenResultados.TERMINO_INVALIDO, None, err_proc_desc_directo\n",
        "                logger.info(f\"Resultados directos: {len(res_directos) if res_directos is not None else 0}\")\n",
        "            except Exception as e:\n",
        "                logger.exception(\"Error buscando directamente en descripciones.\")\n",
        "                return None, OrigenResultados.ERROR_BUSQUEDA_INTERNA_MOTOR, None, f\"Error interno (desc directa): {e}\"\n",
        "\n",
        "            if res_directos is None or res_directos.empty:\n",
        "                return df_vacio_desc, OrigenResultados.DIRECTO_DESCRIPCION_VACIA, None, None\n",
        "            return res_directos, OrigenResultados.DIRECTO_DESCRIPCION_CON_RESULTADOS, None, None\n",
        "\n",
        "    def _extraer_terminos_diccionario(self, df_coincidencias: pd.DataFrame, cols_nombres: List[str]) -> Set[str]:\n",
        "        terminos_clave: Set[str] = set()\n",
        "        if df_coincidencias is None or df_coincidencias.empty or not cols_nombres:\n",
        "            return terminos_clave\n",
        "\n",
        "        cols_validas = [c for c in cols_nombres if c in df_coincidencias.columns]\n",
        "        if not cols_validas:\n",
        "            logger.warning(\"Columnas de diccionario no existen en coincidencias.\")\n",
        "            return terminos_clave\n",
        "\n",
        "        for col_nombre in cols_validas:\n",
        "            try:\n",
        "                for texto_celda in df_coincidencias[col_nombre].dropna().astype(str):\n",
        "                    palabras = self.extractor_magnitud._normalizar_texto(texto_celda).split()\n",
        "                    terminos_clave.update(p for p in palabras if len(p) > 2 and p.isalnum())\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error extrayendo t√©rminos de col '{col_nombre}': {e}\")\n",
        "\n",
        "        logger.info(f\"{len(terminos_clave)} t√©rminos extra√≠dos del diccionario para b√∫squeda secundaria.\")\n",
        "        if terminos_clave: logger.debug(f\"T√©rminos clave (muestra): {list(terminos_clave)[:10]}...\")\n",
        "        return terminos_clave"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "CPVmX7apc7yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. `interfaz_grafica.py`"
      ],
      "metadata": {
        "id": "cT1C3DxKc7yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interfaz_grafica.py\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox, filedialog\n",
        "import pandas as pd\n",
        "import platform\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "from motor_busqueda import MotorBusqueda\n",
        "from enums import OrigenResultados\n",
        "from config import CONFIG_FILE_NAME # Importar el nombre del archivo de configuraci√≥n\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class InterfazGrafica(tk.Tk):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.title(\"Buscador Avanzado (v0.7.1 - Mapeo Magnitudes)\")\n",
        "        self.geometry(\"1250x800\") # Considerar mover a config.py\n",
        "\n",
        "        self.config = self._cargar_configuracion()\n",
        "        indices_cfg = self.config.get(\"indices_columnas_busqueda_dic\", [])\n",
        "        self.motor = MotorBusqueda(indices_diccionario_cfg=indices_cfg)\n",
        "\n",
        "        self.resultados_actuales: Optional[pd.DataFrame] = None\n",
        "        self.texto_busqueda_var = tk.StringVar(self)\n",
        "        self.texto_busqueda_var.trace_add(\"write\", self._on_texto_busqueda_change)\n",
        "        self.ultimo_termino_buscado: Optional[str] = None\n",
        "        self.reglas_guardadas: List[Dict[str, Any]] = []\n",
        "\n",
        "        self.fcds_de_ultima_busqueda: Optional[pd.DataFrame] = None\n",
        "        self.desc_finales_de_ultima_busqueda: Optional[pd.DataFrame] = None\n",
        "\n",
        "        self.origen_principal_resultados: OrigenResultados = OrigenResultados.NINGUNO\n",
        "        self.color_fila_par = \"white\"; self.color_fila_impar = \"#f0f0f0\"\n",
        "        self.op_buttons: Dict[str, ttk.Button] = {}\n",
        "\n",
        "        self._configurar_estilo_ttk()\n",
        "        self._crear_widgets()\n",
        "        self._configurar_grid()\n",
        "        self._configurar_eventos()\n",
        "        self._configurar_tags_treeview()\n",
        "        self._configurar_orden_tabla(self.tabla_resultados)\n",
        "        self._configurar_orden_tabla(self.tabla_diccionario)\n",
        "\n",
        "        self._actualizar_estado(\"Listo. Cargue Diccionario y Descripciones.\")\n",
        "        self._deshabilitar_botones_operadores()\n",
        "        self._actualizar_botones_estado_general()\n",
        "        logger.info(\"Interfaz Gr√°fica (v0.7.1 - Mapeo) inicializada.\")\n",
        "\n",
        "    def _on_texto_busqueda_change(self, var_name: str, index: str, mode: str):\n",
        "        self._actualizar_estado_botones_operadores()\n",
        "\n",
        "    def _cargar_configuracion(self) -> Dict:\n",
        "        config = {}\n",
        "        if os.path.exists(CONFIG_FILE_NAME): # Usar constante de config.py\n",
        "            try:\n",
        "                with open(CONFIG_FILE_NAME, 'r', encoding='utf-8') as f: config = json.load(f)\n",
        "                logger.info(f\"Configuraci√≥n cargada desde: {CONFIG_FILE_NAME}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error al cargar config: {e}\")\n",
        "        else:\n",
        "            logger.info(f\"Archivo de configuraci√≥n '{CONFIG_FILE_NAME}' no encontrado. Se crear√° al cerrar.\")\n",
        "\n",
        "        last_dic_path_str = config.get(\"last_dic_path\")\n",
        "        config[\"last_dic_path\"] = str(Path(last_dic_path_str)) if last_dic_path_str else None\n",
        "        last_desc_path_str = config.get(\"last_desc_path\")\n",
        "        config[\"last_desc_path\"] = str(Path(last_desc_path_str)) if last_desc_path_str else None\n",
        "        config.setdefault(\"indices_columnas_busqueda_dic\", [])\n",
        "        return config\n",
        "\n",
        "    def _guardar_configuracion(self):\n",
        "        self.config[\"last_dic_path\"] = str(self.motor.archivo_diccionario_actual) if self.motor.archivo_diccionario_actual else None\n",
        "        self.config[\"last_desc_path\"] = str(self.motor.archivo_descripcion_actual) if self.motor.archivo_descripcion_actual else None\n",
        "        self.config[\"indices_columnas_busqueda_dic\"] = self.motor.indices_columnas_busqueda_dic\n",
        "        try:\n",
        "            with open(CONFIG_FILE_NAME, 'w', encoding='utf-8') as f: # Usar constante de config.py\n",
        "                json.dump(self.config, f, indent=4)\n",
        "            logger.info(f\"Configuraci√≥n guardada en: {CONFIG_FILE_NAME}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error al guardar config: {e}\")\n",
        "            messagebox.showerror(\"Error Configuraci√≥n\", f\"No se pudo guardar config:\\n{e}\")\n",
        "\n",
        "    def _configurar_estilo_ttk(self):\n",
        "        style = ttk.Style(self); themes = style.theme_names(); os_name = platform.system()\n",
        "        prefs = {\"Windows\":[\"vista\",\"xpnative\",\"clam\"],\"Darwin\":[\"aqua\",\"clam\"],\"Linux\":[\"clam\",\"alt\",\"default\"]}\n",
        "        theme_to_use = next((t for t in prefs.get(os_name, [\"clam\",\"default\"]) if t in themes), None)\n",
        "        if not theme_to_use:\n",
        "            theme_to_use = style.theme_use() if style.theme_use() else (\"default\" if \"default\" in themes else (themes[0] if themes else None))\n",
        "        if theme_to_use:\n",
        "            logger.info(f\"Aplicando tema TTK: {theme_to_use}\")\n",
        "            try:\n",
        "                style.theme_use(theme_to_use)\n",
        "                style.configure(\"Operator.TButton\", padding=(2, 1), font=('TkDefaultFont', 9))\n",
        "            except tk.TclError as e: logger.warning(f\"No se pudo aplicar tema '{theme_to_use}': {e}.\")\n",
        "        else: logger.warning(\"No se encontr√≥ tema TTK disponible.\")\n",
        "\n",
        "    def _crear_widgets(self):\n",
        "        self.marco_controles = ttk.LabelFrame(self, text=\"Controles\")\n",
        "        self.btn_cargar_diccionario = ttk.Button(self.marco_controles, text=\"Cargar Diccionario\", command=self._cargar_diccionario)\n",
        "        self.lbl_dic_cargado = ttk.Label(self.marco_controles, text=\"Dic: Ninguno\", width=20, anchor=tk.W, relief=tk.SUNKEN, borderwidth=1)\n",
        "        self.btn_cargar_descripciones = ttk.Button(self.marco_controles, text=\"Cargar Descripciones\", command=self._cargar_excel_descripcion)\n",
        "        self.lbl_desc_cargado = ttk.Label(self.marco_controles, text=\"Desc: Ninguno\", width=20, anchor=tk.W, relief=tk.SUNKEN, borderwidth=1)\n",
        "\n",
        "        self.frame_ops = ttk.Frame(self.marco_controles)\n",
        "        op_buttons_defs = [\n",
        "            (\"+\", \"+\"), (\"|\", \"|\"), (\"#\", \"#\"), (\">\", \">\"),\n",
        "            (\"<\", \"<\"), (\"‚â•\", \">=\"), (\"‚â§\", \"<=\"), (\"-\", \"-\")\n",
        "        ]\n",
        "        for i, (text, op_val) in enumerate(op_buttons_defs):\n",
        "            btn = ttk.Button(\n",
        "                self.frame_ops, text=text,\n",
        "                command=lambda op=op_val: self._insertar_operador_validado(op),\n",
        "                style=\"Operator.TButton\", width=3\n",
        "            )\n",
        "            btn.grid(row=0, column=i, padx=1, pady=1, sticky=\"nsew\")\n",
        "            self.op_buttons[op_val] = btn\n",
        "\n",
        "        self.entrada_busqueda = ttk.Entry(self.marco_controles, width=50, textvariable=self.texto_busqueda_var)\n",
        "        self.btn_buscar = ttk.Button(self.marco_controles, text=\"Buscar\", command=self._ejecutar_busqueda)\n",
        "        self.btn_salvar_regla = ttk.Button(self.marco_controles, text=\"Salvar Regla\", command=self._salvar_regla_actual)\n",
        "        self.btn_ayuda = ttk.Button(self.marco_controles, text=\"?\", command=self._mostrar_ayuda, width=3)\n",
        "        self.btn_exportar = ttk.Button(self.marco_controles, text=\"Exportar\", command=self._exportar_resultados)\n",
        "\n",
        "        self.lbl_tabla_diccionario = ttk.Label(self, text=\"Vista Previa Diccionario:\")\n",
        "        self.lbl_tabla_resultados = ttk.Label(self, text=\"Resultados / Descripciones:\")\n",
        "\n",
        "        self.frame_tabla_diccionario = ttk.Frame(self)\n",
        "        self.tabla_diccionario = ttk.Treeview(self.frame_tabla_diccionario, show=\"headings\", height=8)\n",
        "        self.scrolly_diccionario = ttk.Scrollbar(self.frame_tabla_diccionario, orient=\"vertical\", command=self.tabla_diccionario.yview)\n",
        "        self.scrollx_diccionario = ttk.Scrollbar(self.frame_tabla_diccionario, orient=\"horizontal\", command=self.tabla_diccionario.xview)\n",
        "        self.tabla_diccionario.configure(yscrollcommand=self.scrolly_diccionario.set, xscrollcommand=self.scrollx_diccionario.set)\n",
        "\n",
        "        self.frame_tabla_resultados = ttk.Frame(self)\n",
        "        self.tabla_resultados = ttk.Treeview(self.frame_tabla_resultados, show=\"headings\")\n",
        "        self.scrolly_resultados = ttk.Scrollbar(self.frame_tabla_resultados, orient=\"vertical\", command=self.tabla_resultados.yview)\n",
        "        self.scrollx_resultados = ttk.Scrollbar(self.frame_tabla_resultados, orient=\"horizontal\", command=self.tabla_resultados.xview)\n",
        "        self.tabla_resultados.configure(yscrollcommand=self.scrolly_resultados.set, xscrollcommand=self.scrollx_resultados.set)\n",
        "\n",
        "        self.barra_estado = ttk.Label(self, text=\"\", relief=tk.SUNKEN, anchor=tk.W, borderwidth=1)\n",
        "        self._actualizar_etiquetas_archivos()\n",
        "\n",
        "    def _configurar_grid(self):\n",
        "        self.grid_rowconfigure(2, weight=1); self.grid_rowconfigure(4, weight=3)\n",
        "        self.grid_columnconfigure(0, weight=1)\n",
        "        self.marco_controles.grid(row=0, column=0, sticky=\"new\", padx=10, pady=(10, 5))\n",
        "        self.marco_controles.grid_columnconfigure(1, weight=1)\n",
        "        self.marco_controles.grid_columnconfigure(3, weight=1)\n",
        "\n",
        "        self.btn_cargar_diccionario.grid(row=0, column=0, padx=(5,0), pady=5, sticky=\"w\")\n",
        "        self.lbl_dic_cargado.grid(row=0, column=1, padx=(2,10), pady=5, sticky=\"ew\")\n",
        "        self.btn_cargar_descripciones.grid(row=0, column=2, padx=(5,0), pady=5, sticky=\"w\")\n",
        "        self.lbl_desc_cargado.grid(row=0, column=3, padx=(2,5), pady=5, sticky=\"ew\")\n",
        "\n",
        "        self.frame_ops.grid(row=1, column=0, columnspan=4, padx=5, pady=(5,0), sticky=\"ew\")\n",
        "        for i in range(len(self.op_buttons)): self.frame_ops.grid_columnconfigure(i, weight=1)\n",
        "\n",
        "        self.entrada_busqueda.grid(row=2, column=0, columnspan=2, padx=5, pady=(0,5), sticky=\"ew\")\n",
        "        self.btn_buscar.grid(row=2, column=2, padx=(2,0), pady=(0,5), sticky=\"w\")\n",
        "        self.btn_salvar_regla.grid(row=2, column=3, padx=(2,0), pady=(0,5), sticky=\"w\")\n",
        "        self.btn_ayuda.grid(row=2, column=4, padx=(2,0), pady=(0,5), sticky=\"w\")\n",
        "        self.btn_exportar.grid(row=2, column=5, padx=(10, 5), pady=(0,5), sticky=\"e\")\n",
        "\n",
        "        self.lbl_tabla_diccionario.grid(row=1, column=0, sticky=\"sw\", padx=10, pady=(10, 0))\n",
        "        self.frame_tabla_diccionario.grid(row=2, column=0, sticky=\"nsew\", padx=10, pady=(0, 10))\n",
        "        self.frame_tabla_diccionario.grid_rowconfigure(0, weight=1); self.frame_tabla_diccionario.grid_columnconfigure(0, weight=1)\n",
        "        self.tabla_diccionario.grid(row=0, column=0, sticky=\"nsew\"); self.scrolly_diccionario.grid(row=0, column=1, sticky=\"ns\"); self.scrollx_diccionario.grid(row=1, column=0, sticky=\"ew\")\n",
        "\n",
        "        self.lbl_tabla_resultados.grid(row=3, column=0, sticky=\"sw\", padx=10, pady=(0, 0))\n",
        "        self.frame_tabla_resultados.grid(row=4, column=0, sticky=\"nsew\", padx=10, pady=(0, 10))\n",
        "        self.frame_tabla_resultados.grid_rowconfigure(0, weight=1); self.frame_tabla_resultados.grid_columnconfigure(0, weight=1)\n",
        "        self.tabla_resultados.grid(row=0, column=0, sticky=\"nsew\"); self.scrolly_resultados.grid(row=0, column=1, sticky=\"ns\"); self.scrollx_resultados.grid(row=1, column=0, sticky=\"ew\")\n",
        "\n",
        "        self.barra_estado.grid(row=5, column=0, sticky=\"sew\", padx=0, pady=(5, 0))\n",
        "\n",
        "    def _configurar_eventos(self):\n",
        "        self.entrada_busqueda.bind(\"<Return>\", lambda event: self._ejecutar_busqueda())\n",
        "        self.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
        "\n",
        "    def _actualizar_estado(self, mensaje: str):\n",
        "        self.barra_estado.config(text=mensaje)\n",
        "        logger.info(f\"Estado UI: {mensaje}\")\n",
        "        self.update_idletasks()\n",
        "\n",
        "    def _mostrar_ayuda(self):\n",
        "        # El texto de ayuda permanece igual, ya que la sintaxis de b√∫squeda para el usuario no ha cambiado.\n",
        "        ayuda = \"\"\"Sintaxis de B√∫squeda:\n",
        "-------------------------------------\n",
        "- Texto simple: Busca la palabra o frase (insensible a may√∫s/min√∫s y acentos). Ej: `router cisco`\n",
        "- Operadores L√≥gicos:\n",
        "  * `t√©rmino1 + t√©rmino2`: Busca filas con AMBOS (AND). Ej: `tarjeta + 16 puertos`\n",
        "  * `t√©rmino1 | t√©rmino2` (o `/`): Busca filas con AL MENOS UNO (OR). Ej: `modulo | SFP`\n",
        "- Comparaciones num√©ricas (unidad opcional, si se usa debe coincidir con mapeo interno):\n",
        "  * `>num[UNIDAD]`: Mayor. Ej: `>1000` o `>1000w`\n",
        "  * `<num[UNIDAD]`: Menor. Ej: `<50` o `<50v`\n",
        "  * `>=num[UNIDAD]` o `‚â•num[UNIDAD]`: Mayor o igual. Ej: `>=48a`\n",
        "  * `<=num[UNIDAD]` o `‚â§num[UNIDAD]`: Menor o igual. Ej: `<=10.5w`\n",
        "- Rangos num√©ricos (unidad opcional, ambos extremos incluidos):\n",
        "  * `num1-num2[UNIDAD]`: Entre num1 y num2. Ej: `10-20` o `50-100V`\n",
        "- Negaci√≥n (excluir):\n",
        "  * `#t√©rmino`: `t√©rmino` puede ser texto, comparaci√≥n o rango.\n",
        "    Ej: `switch + #gestionable`\n",
        "    Ej: `tarjeta + #>8 puertos`\n",
        "\n",
        "Modo de B√∫squeda:\n",
        "1. El t√©rmino se busca primero en el Diccionario.\n",
        "2. Si hay coincidencias (FCDs), se extraen textos y se buscan en Descripciones.\n",
        "3. Si no, se preguntar√° para buscar el t√©rmino original directamente en Descripciones.\n",
        "4. B√∫squeda vac√≠a: Muestra todas las descripciones.\n",
        "\"\"\"\n",
        "        messagebox.showinfo(\"Ayuda - Sintaxis de B√∫squeda\", ayuda)\n",
        "\n",
        "    def _configurar_tags_treeview(self):\n",
        "        for tabla in [self.tabla_diccionario, self.tabla_resultados]:\n",
        "            tabla.tag_configure('par', background=self.color_fila_par)\n",
        "            tabla.tag_configure('impar', background=self.color_fila_impar)\n",
        "\n",
        "    def _configurar_orden_tabla(self, tabla: ttk.Treeview):\n",
        "        cols = tabla[\"columns\"]\n",
        "        if cols:\n",
        "            for col in cols:\n",
        "                tabla.heading(col, text=str(col), anchor=tk.W,\n",
        "                              command=lambda c=col, t=tabla: self._ordenar_columna(t, c, False))\n",
        "\n",
        "    def _ordenar_columna(self, tabla: ttk.Treeview, col: str, reverse: bool):\n",
        "        df_para_ordenar = None\n",
        "        if tabla == self.tabla_diccionario:\n",
        "            df_para_ordenar = self.motor.datos_diccionario\n",
        "        elif tabla == self.tabla_resultados:\n",
        "            df_para_ordenar = self.resultados_actuales\n",
        "\n",
        "        if df_para_ordenar is None or df_para_ordenar.empty or col not in df_para_ordenar.columns:\n",
        "            logging.debug(f\"No se puede ordenar tabla por columna '{col}'.\")\n",
        "            tabla.heading(col, command=lambda c=col, t=tabla: self._ordenar_columna(t, c, not reverse))\n",
        "            return\n",
        "\n",
        "        logging.info(f\"Ordenando tabla por columna '{col}', descendente={reverse}\")\n",
        "        try:\n",
        "            col_to_sort_by = df_para_ordenar[col]\n",
        "            try: # Intento de orden num√©rico inteligente\n",
        "                nan_mask = pd.to_numeric(col_to_sort_by, errors='coerce').isna()\n",
        "                numeric_part = col_to_sort_by[~nan_mask]\n",
        "                nan_part = col_to_sort_by[nan_mask]\n",
        "\n",
        "                if not numeric_part.empty:\n",
        "                    temp_numeric = pd.to_numeric(numeric_part, errors='coerce')\n",
        "                    if not temp_numeric.isna().all():\n",
        "                        sorted_numeric_indices = temp_numeric.sort_values(ascending=not reverse).index\n",
        "                        final_order_indices = sorted_numeric_indices.tolist() + nan_part.index.tolist()\n",
        "                        df_ordenado = df_para_ordenar.loc[final_order_indices]\n",
        "                    else: raise ValueError(\"No convertible a num√©rico fiable\")\n",
        "                else:\n",
        "                    df_ordenado = df_para_ordenar.sort_values(by=col, ascending=not reverse, na_position='last', key=lambda x: x.astype(str).str.lower())\n",
        "            except (ValueError, TypeError): # Fallback a ordenaci√≥n de texto\n",
        "                df_ordenado = df_para_ordenar.sort_values(\n",
        "                    by=col, ascending=not reverse, na_position='last',\n",
        "                    key=lambda x: x.astype(str).str.lower() if pd.api.types.is_string_dtype(x) or pd.api.types.is_object_dtype(x) else x\n",
        "                )\n",
        "\n",
        "            if tabla == self.tabla_diccionario:\n",
        "                self.motor.datos_diccionario = df_ordenado\n",
        "                self._actualizar_tabla(tabla, df_ordenado, limite_filas=100)\n",
        "            elif tabla == self.tabla_resultados:\n",
        "                self.resultados_actuales = df_ordenado\n",
        "                self._actualizar_tabla(tabla, df_ordenado)\n",
        "\n",
        "            tabla.heading(col, command=lambda c=col, t=tabla: self._ordenar_columna(t, c, not reverse))\n",
        "            self._actualizar_estado(f\"Tabla ordenada por '{col}' ({'Asc' if not reverse else 'Desc'}).\")\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Error ordenando por columna '{col}'\")\n",
        "            messagebox.showerror(\"Error al Ordenar\", f\"No se pudo ordenar por '{col}':\\n{e}\")\n",
        "            tabla.heading(col, command=lambda c=col, t=tabla: self._ordenar_columna(t, c, False))\n",
        "\n",
        "\n",
        "    def _actualizar_tabla(self, tabla: ttk.Treeview, datos: Optional[pd.DataFrame], limite_filas: Optional[int] = None, columnas_a_mostrar: Optional[List[str]] = None):\n",
        "        is_diccionario = tabla == self.tabla_diccionario\n",
        "        logger.debug(f\"Actualizando tabla {'Diccionario' if is_diccionario else 'Resultados'}.\")\n",
        "        try:\n",
        "            for i in tabla.get_children(): tabla.delete(i)\n",
        "        except tk.TclError as e: logger.warning(f\"Error Tcl limpiando tabla: {e}\"); pass\n",
        "        tabla[\"columns\"] = ()\n",
        "\n",
        "        if datos is None or datos.empty:\n",
        "            logger.debug(\"Sin datos para mostrar en tabla.\")\n",
        "            self._configurar_orden_tabla(tabla)\n",
        "            return\n",
        "\n",
        "        cols_df = list(datos.columns)\n",
        "        cols_finales = [c for c in (columnas_a_mostrar or cols_df) if c in cols_df] or cols_df\n",
        "\n",
        "        if not cols_finales:\n",
        "            logger.warning(\"DataFrame sin columnas o columnas seleccionadas no existen.\")\n",
        "            self._configurar_orden_tabla(tabla)\n",
        "            return\n",
        "\n",
        "        df_vista = datos[cols_finales]\n",
        "        tabla[\"columns\"] = tuple(cols_finales)\n",
        "\n",
        "        for col in cols_finales:\n",
        "            tabla.heading(col, text=str(col), anchor=tk.W)\n",
        "            try:\n",
        "                col_str = df_vista[col].astype(str)\n",
        "                ancho_cont = col_str.str.len().max() if not col_str.empty else 0\n",
        "                ancho_cab = len(str(col))\n",
        "                ancho = max(70, min(int(max(ancho_cab * 8, ancho_cont * 6.5) + 25), 400))\n",
        "                tabla.column(col, anchor=tk.W, width=ancho, minwidth=70)\n",
        "            except Exception:\n",
        "                tabla.column(col, anchor=tk.W, width=100, minwidth=50)\n",
        "\n",
        "        num_iterar = limite_filas if is_diccionario and limite_filas is not None else len(df_vista)\n",
        "        df_iterar = df_vista.head(num_iterar)\n",
        "\n",
        "        for i, (_, row) in enumerate(df_iterar.iterrows()):\n",
        "            vals = [str(v) if pd.notna(v) else \"\" for v in row.values]\n",
        "            tag = 'par' if i % 2 == 0 else 'impar'\n",
        "            try:\n",
        "                tabla.insert(\"\", \"end\", values=vals, tags=(tag,))\n",
        "            except tk.TclError:\n",
        "                try:\n",
        "                    vals_ascii = [v.encode('ascii', 'ignore').decode('ascii') for v in vals]\n",
        "                    tabla.insert(\"\", \"end\", values=vals_ascii, tags=(tag,))\n",
        "                except Exception as e_inner:\n",
        "                    logger.error(f\"Fallo fallback ASCII fila {i}: {e_inner}\")\n",
        "\n",
        "        self._configurar_orden_tabla(tabla)\n",
        "\n",
        "    def _actualizar_etiquetas_archivos(self):\n",
        "        dic_p = self.motor.archivo_diccionario_actual\n",
        "        desc_p = self.motor.archivo_descripcion_actual\n",
        "        dic_n = dic_p.name if dic_p else \"Ninguno\"\n",
        "        desc_n = desc_p.name if desc_p else \"Ninguno\"\n",
        "\n",
        "        max_l = 25\n",
        "        dic_d = f\"Dic: {dic_n}\" if len(dic_n) <= max_l else f\"Dic: ...{dic_n[-(max_l-4):]}\"\n",
        "        desc_d = f\"Desc: {desc_n}\" if len(desc_n) <= max_l else f\"Desc: ...{desc_n[-(max_l-4):]}\"\n",
        "\n",
        "        self.lbl_dic_cargado.config(text=dic_d, foreground=\"green\" if dic_p else \"red\")\n",
        "        self.lbl_desc_cargado.config(text=desc_d, foreground=\"green\" if desc_p else \"red\")\n",
        "\n",
        "    def _actualizar_botones_estado_general(self):\n",
        "        dic_ok = self.motor.datos_diccionario is not None\n",
        "        desc_ok = self.motor.datos_descripcion is not None\n",
        "\n",
        "        if dic_ok or desc_ok: self._actualizar_estado_botones_operadores()\n",
        "        else: self._deshabilitar_botones_operadores()\n",
        "\n",
        "        self.btn_buscar['state'] = 'normal' if dic_ok and desc_ok else 'disabled'\n",
        "\n",
        "        salvar_ok = False\n",
        "        if self.ultimo_termino_buscado and self.origen_principal_resultados != OrigenResultados.NINGUNO:\n",
        "            if self.origen_principal_resultados.es_via_diccionario:\n",
        "                if (self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty) or \\\n",
        "                   (self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and \\\n",
        "                    self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC):\n",
        "                    salvar_ok = True\n",
        "            elif self.origen_principal_resultados.es_directo_descripcion or \\\n",
        "                 self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA:\n",
        "                if self.desc_finales_de_ultima_busqueda is not None: salvar_ok = True\n",
        "\n",
        "        self.btn_salvar_regla['state'] = 'normal' if salvar_ok else 'disabled'\n",
        "        self.btn_exportar['state'] = 'normal' if self.reglas_guardadas else 'disabled'\n",
        "\n",
        "    def _cargar_diccionario(self):\n",
        "        last_dir = str(Path(self.config.get(\"last_dic_path\",\"\")).parent) if self.config.get(\"last_dic_path\") and Path(self.config.get(\"last_dic_path\",\"\")).exists() else os.getcwd()\n",
        "        ruta = filedialog.askopenfilename(title=\"Cargar Diccionario\", filetypes=[(\"Excel\", \"*.xlsx *.xls\")], initialdir=last_dir)\n",
        "        if not ruta: return\n",
        "\n",
        "        self._actualizar_estado(f\"Cargando diccionario: {Path(ruta).name}...\")\n",
        "        self._actualizar_tabla(self.tabla_diccionario, None); self._actualizar_tabla(self.tabla_resultados, None)\n",
        "        self.resultados_actuales = self.fcds_de_ultima_busqueda = self.desc_finales_de_ultima_busqueda = None\n",
        "        self.origen_principal_resultados = OrigenResultados.NINGUNO\n",
        "\n",
        "        exito, msg = self.motor.cargar_excel_diccionario(ruta)\n",
        "        if exito:\n",
        "            self.config[\"last_dic_path\"] = ruta; self._guardar_configuracion()\n",
        "            df_dic = self.motor.datos_diccionario\n",
        "            if df_dic is not None:\n",
        "                n_filas = len(df_dic)\n",
        "                cols_b, _ = self.motor._obtener_nombres_columnas_busqueda_df(df_dic, self.motor.indices_columnas_busqueda_dic, \"dic (preview)\")\n",
        "                idxs_str = ', '.join(map(str, self.motor.indices_columnas_busqueda_dic or [])) if self.motor.indices_columnas_busqueda_dic and self.motor.indices_columnas_busqueda_dic != [-1] else \"Todas Texto\"\n",
        "                lbl_txt = f\"Vista Previa Dic ({n_filas} filas)\" + (f\" (Cols: {', '.join(cols_b)} - Idx: {idxs_str})\" if cols_b else \"\")\n",
        "                self.lbl_tabla_diccionario.config(text=lbl_txt)\n",
        "                self._actualizar_tabla(self.tabla_diccionario, df_dic, limite_filas=100, columnas_a_mostrar=cols_b)\n",
        "                self.title(f\"Buscador - Dic: {Path(ruta).name}\")\n",
        "                self._actualizar_estado(f\"Diccionario '{Path(ruta).name}' ({n_filas} filas) cargado.\")\n",
        "        else:\n",
        "            self._actualizar_estado(f\"Error cargando diccionario: {msg or 'Desconocido'}\")\n",
        "            if msg: messagebox.showerror(\"Error Carga Diccionario\", msg)\n",
        "            self.title(\"Buscador Avanzado (v0.7.1 - Mapeo Magnitudes)\")\n",
        "        self._actualizar_etiquetas_archivos()\n",
        "        self._actualizar_botones_estado_general()\n",
        "\n",
        "    def _cargar_excel_descripcion(self):\n",
        "        last_dir = str(Path(self.config.get(\"last_desc_path\",\"\")).parent) if self.config.get(\"last_desc_path\") and Path(self.config.get(\"last_desc_path\",\"\")).exists() else os.getcwd()\n",
        "        ruta = filedialog.askopenfilename(title=\"Cargar Descripciones\", filetypes=[(\"Excel\", \"*.xlsx *.xls\")], initialdir=last_dir)\n",
        "        if not ruta: return\n",
        "\n",
        "        self._actualizar_estado(f\"Cargando descripciones: {Path(ruta).name}...\")\n",
        "        self.resultados_actuales = self.desc_finales_de_ultima_busqueda = None\n",
        "        self.origen_principal_resultados = OrigenResultados.NINGUNO\n",
        "        self._actualizar_tabla(self.tabla_resultados, None)\n",
        "\n",
        "        exito, msg = self.motor.cargar_excel_descripcion(ruta)\n",
        "        if exito:\n",
        "            self.config[\"last_desc_path\"] = ruta; self._guardar_configuracion()\n",
        "            df_desc = self.motor.datos_descripcion\n",
        "            if df_desc is not None:\n",
        "                n_filas = len(df_desc)\n",
        "                self._actualizar_estado(f\"Descripciones '{Path(ruta).name}' ({n_filas} filas) cargadas.\")\n",
        "                self._actualizar_tabla(self.tabla_resultados, df_desc)\n",
        "                dic_title = Path(self.motor.archivo_diccionario_actual or \"\").name or \"N/A\"\n",
        "                self.title(f\"Buscador - Dic: {dic_title} | Desc: {Path(ruta).name}\")\n",
        "        else:\n",
        "            self._actualizar_estado(f\"Error cargando descripciones: {msg or 'Desconocido'}\")\n",
        "            if msg: messagebox.showerror(\"Error Carga Descripciones\", msg)\n",
        "            dic_title = Path(self.motor.archivo_diccionario_actual or \"\").name or \"N/A\"\n",
        "            self.title(f\"Buscador - Dic: {dic_title} | Desc: N/A\" if self.motor.archivo_diccionario_actual else \"Buscador Avanzado (v0.7.1)\")\n",
        "        self._actualizar_etiquetas_archivos()\n",
        "        self._actualizar_botones_estado_general()\n",
        "\n",
        "    def _ejecutar_busqueda(self):\n",
        "        if not self.motor.datos_diccionario or not self.motor.datos_descripcion:\n",
        "            messagebox.showwarning(\"Archivos Faltantes\", \"Cargue Diccionario y Descripciones.\")\n",
        "            return\n",
        "\n",
        "        term = self.texto_busqueda_var.get()\n",
        "        self.ultimo_termino_buscado = term\n",
        "        self.resultados_actuales = self.fcds_de_ultima_busqueda = self.desc_finales_de_ultima_busqueda = None\n",
        "        self.origen_principal_resultados = OrigenResultados.NINGUNO\n",
        "        self._actualizar_tabla(self.tabla_resultados, None)\n",
        "        self._actualizar_estado(f\"Buscando '{term}'...\")\n",
        "\n",
        "        res_df, origen, fcds, err_msg = self.motor.buscar(term, True)\n",
        "        self.fcds_de_ultima_busqueda = fcds; self.origen_principal_resultados = origen\n",
        "        df_desc_cols = self.motor.datos_descripcion.columns if self.motor.datos_descripcion is not None else []\n",
        "\n",
        "        if err_msg and (origen.es_error_operacional or origen.es_termino_invalido) : # Error cr√≠tico del motor\n",
        "             messagebox.showerror(\"Error de B√∫squeda (Motor)\", f\"Error: {err_msg}\")\n",
        "             self._actualizar_estado(f\"Error en motor: {err_msg}\")\n",
        "             self.resultados_actuales = pd.DataFrame(columns=df_desc_cols)\n",
        "        elif origen.es_error_carga or origen.es_error_configuracion :\n",
        "             msg_sh = err_msg or f\"Error: {origen.name}\"\n",
        "             messagebox.showerror(\"Error de B√∫squeda\", msg_sh)\n",
        "             self._actualizar_estado(msg_sh)\n",
        "             self.resultados_actuales = pd.DataFrame(columns=df_desc_cols)\n",
        "        elif origen == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC:\n",
        "            self.resultados_actuales = res_df\n",
        "            self._actualizar_estado(f\"'{term}': {len(fcds or [])} en Dic, {len(res_df or [])} en Desc.\")\n",
        "        elif origen in [OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC, OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS] or \\\n",
        "             (fcds is not None and fcds.empty and origen == OrigenResultados.VIA_DICCIONARIO_SIN_RESULTADOS_DESC):\n",
        "            self.resultados_actuales = res_df # DF vac√≠o\n",
        "            msg_fcd_info = f\"{len(fcds or [])} coincidencias en Diccionario\" if fcds is not None and not fcds.empty else \"Ninguna coincidencia en Diccionario\"\n",
        "            msg_desc_issue = \"pero no se extrajeron t√©rminos para Desc.\" if origen == OrigenResultados.VIA_DICCIONARIO_SIN_TERMINOS_VALIDOS else \"sin resultados en Desc.\"\n",
        "            self._actualizar_estado(f\"'{term}': {msg_fcd_info}, {msg_desc_issue.split('.')[0]}.\")\n",
        "            if messagebox.askyesno(\"B√∫squeda Alternativa\", f\"{msg_fcd_info} para '{term}', {msg_desc_issue}\\n\\nBuscar '{term}' directo en Descripciones?\"):\n",
        "                self._actualizar_estado(f\"Buscando directo '{term}' en descripciones...\")\n",
        "                res_df_dir, origen_dir, _, err_msg_dir = self.motor.buscar(term, False)\n",
        "                if err_msg_dir and (origen_dir.es_error_operacional or origen_dir.es_termino_invalido):\n",
        "                     messagebox.showerror(\"Error B√∫squeda Directa\", f\"Error: {err_msg_dir}\")\n",
        "                     self._actualizar_estado(f\"Error b√∫squeda directa: {err_msg_dir}\")\n",
        "                elif origen_dir.es_error_carga or origen_dir.es_error_configuracion:\n",
        "                     msg_sh_dir = err_msg_dir or f\"Error en b√∫squeda directa: {origen_dir.name}\"\n",
        "                     messagebox.showerror(\"Error B√∫squeda Directa\", msg_sh_dir)\n",
        "                     self._actualizar_estado(msg_sh_dir)\n",
        "                else:\n",
        "                    self.resultados_actuales = res_df_dir; self.origen_principal_resultados = origen_dir\n",
        "                    self.fcds_de_ultima_busqueda = None\n",
        "                    num_rdd = len(self.resultados_actuales or [])\n",
        "                    self._actualizar_estado(f\"B√∫squeda directa '{term}': {num_rdd} resultados.\")\n",
        "                    if num_rdd == 0 and origen_dir == OrigenResultados.DIRECTO_DESCRIPCION_VACIA and term.strip():\n",
        "                        messagebox.showinfo(\"Informaci√≥n\", f\"No se encontraron resultados para '{term}' directo.\")\n",
        "        elif origen == OrigenResultados.DIRECTO_DESCRIPCION_CON_RESULTADOS :\n",
        "            self.resultados_actuales = res_df\n",
        "            self._actualizar_estado(f\"B√∫squeda directa '{term}': {len(res_df or [])} resultados.\")\n",
        "        elif origen == OrigenResultados.DIRECTO_DESCRIPCION_VACIA:\n",
        "            self.resultados_actuales = res_df\n",
        "            self._actualizar_estado(f\"B√∫squeda directa '{term}': 0 resultados.\")\n",
        "            if term.strip(): messagebox.showinfo(\"Informaci√≥n\", f\"No se encontraron resultados para '{term}' directo.\")\n",
        "\n",
        "        if self.resultados_actuales is None: self.resultados_actuales = pd.DataFrame(columns=df_desc_cols)\n",
        "        self.desc_finales_de_ultima_busqueda = self.resultados_actuales.copy()\n",
        "        self._actualizar_tabla(self.tabla_resultados, self.resultados_actuales)\n",
        "        self._actualizar_botones_estado_general()\n",
        "        if self.motor.datos_diccionario is not None and not self.motor.datos_diccionario.empty:\n",
        "            self._buscar_y_enfocar_en_preview()\n",
        "\n",
        "    def _buscar_y_enfocar_en_preview(self): # Simplificado para brevedad, la l√≥gica es de UI\n",
        "        df_dic = self.motor.datos_diccionario\n",
        "        if df_dic is None or df_dic.empty: return\n",
        "        term_raw = self.texto_busqueda_var.get()\n",
        "        if not term_raw.strip(): return\n",
        "\n",
        "        op_n1, segs_n1 = self.motor._parsear_nivel1_or(term_raw)\n",
        "        if not segs_n1: return\n",
        "        op_n2, terms_n2 = self.motor._parsear_nivel2_and(segs_n1[0])\n",
        "        if not terms_n2: return\n",
        "        term_focus_raw = terms_n2[0][1:].strip() if terms_n2[0].startswith(\"#\") else terms_n2[0].strip()\n",
        "        if not term_focus_raw: return\n",
        "        term_focus_norm = self.motor.extractor_magnitud._normalizar_texto(term_focus_raw)\n",
        "        if not term_focus_norm: return\n",
        "\n",
        "        items_ids = self.tabla_diccionario.get_children('')\n",
        "        if not items_ids: return\n",
        "\n",
        "        logger.info(f\"Enfocando '{term_focus_norm}' en preview diccionario...\")\n",
        "        found_id = None\n",
        "        cols_preview = self.tabla_diccionario[\"columns\"] or []\n",
        "        # La l√≥gica original para encontrar el item_id era compleja y depend√≠a de la estructura de datos\n",
        "        # en la preview. Aqu√≠ una simplificaci√≥n conceptual:\n",
        "        for item_id in items_ids:\n",
        "            try:\n",
        "                vals = self.tabla_diccionario.item(item_id, 'values')\n",
        "                if any(term_focus_norm in self.motor.extractor_magnitud._normalizar_texto(str(v)) for v in vals if v):\n",
        "                    found_id = item_id; break\n",
        "            except Exception: continue\n",
        "\n",
        "        if found_id:\n",
        "            logger.info(f\"T√©rmino '{term_focus_norm}' enfocado (ID: {found_id}).\")\n",
        "            try:\n",
        "                if self.tabla_diccionario.selection(): self.tabla_diccionario.selection_remove(self.tabla_diccionario.selection())\n",
        "                self.tabla_diccionario.selection_set(found_id); self.tabla_diccionario.see(found_id); self.tabla_diccionario.focus(found_id)\n",
        "            except Exception as e: logger.error(f\"Error enfocando item {found_id}: {e}\")\n",
        "        else: logger.info(f\"T√©rmino '{term_focus_norm}' no enfocado en preview.\")\n",
        "\n",
        "\n",
        "    def _salvar_regla_actual(self): # La l√≥gica interna de esta funci√≥n es extensa y se mantiene\n",
        "        origen_nombre = self.origen_principal_resultados.name\n",
        "        logger.info(f\"Salvando regla. Origen: {origen_nombre}, √öltimo t√©rmino: '{self.ultimo_termino_buscado}'\")\n",
        "\n",
        "        if not self.ultimo_termino_buscado and not (self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA and self.desc_finales_de_ultima_busqueda is not None):\n",
        "            messagebox.showerror(\"Error\", \"No hay t√©rmino de b√∫squeda o resultados v√°lidos.\"); return\n",
        "\n",
        "        term_orig_regla = self.ultimo_termino_buscado or ''\n",
        "        op_n1, segs_n1 = self.motor._parsear_nivel1_or(term_orig_regla)\n",
        "        parsed_segs = []\n",
        "        for seg in segs_n1:\n",
        "            op_n2, terms_n2 = self.motor._parsear_nivel2_and(seg)\n",
        "            parsed_segs.append({\"operador_segmento_and\": op_n2, \"terminos_analizados\": self.motor._analizar_terminos(terms_n2)})\n",
        "\n",
        "        regla_base = {'termino_busqueda_original': term_orig_regla, 'operador_principal_or': op_n1,\n",
        "                      'segmentos_parseados_para_and': parsed_segs, 'fuente_original_guardado': origen_nombre,\n",
        "                      'timestamp': pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "        salvo = False\n",
        "\n",
        "        if self.origen_principal_resultados.es_via_diccionario:\n",
        "            decision = self._mostrar_dialogo_seleccion_salvado_via_diccionario()\n",
        "            if decision['confirmed']:\n",
        "                if decision['save_fcd'] and self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty:\n",
        "                    self.reglas_guardadas.append({**regla_base, 'tipo_datos_guardados': \"COINCIDENCIAS_DICCIONARIO\", 'datos_snapshot': self.fcds_de_ultima_busqueda.to_dict('records')}); salvo = True\n",
        "                if decision['save_rfd'] and self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC:\n",
        "                    self.reglas_guardadas.append({**regla_base, 'tipo_datos_guardados': \"RESULTADOS_DESCRIPCION_VIA_DICCIONARIO\", 'datos_snapshot': self.desc_finales_de_ultima_busqueda.to_dict('records')}); salvo = True\n",
        "        elif self.origen_principal_resultados.es_directo_descripcion or self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA:\n",
        "             if self.desc_finales_de_ultima_busqueda is not None:\n",
        "                tipo = \"TODAS_LAS_DESCRIPCIONES\" if self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA and not term_orig_regla.strip() else \"RESULTADOS_DESCRIPCION_DIRECTA\"\n",
        "                self.reglas_guardadas.append({**regla_base, 'tipo_datos_guardados': tipo, 'datos_snapshot': self.desc_finales_de_ultima_busqueda.to_dict('records')}); salvo = True\n",
        "             else: messagebox.showwarning(\"Sin Datos\", \"No hay resultados de descripci√≥n para salvar.\")\n",
        "        else:\n",
        "            if self.origen_principal_resultados != OrigenResultados.NINGUNO and not (self.origen_principal_resultados.es_error_carga or self.origen_principal_resultados.es_error_configuracion or self.origen_principal_resultados.es_error_operacional or self.origen_principal_resultados.es_termino_invalido):\n",
        "                messagebox.showerror(\"Error\", f\"No se puede determinar qu√© salvar para origen: {origen_nombre}.\")\n",
        "            else: messagebox.showwarning(\"Nada que Salvar\", \"No hay resultados v√°lidos para salvar.\")\n",
        "\n",
        "        if salvo: self._actualizar_estado(f\"Regla(s) guardada(s). Total: {len(self.reglas_guardadas)}.\")\n",
        "        elif self.ultimo_termino_buscado or self.origen_principal_resultados == OrigenResultados.DIRECTO_DESCRIPCION_VACIA :\n",
        "            self._actualizar_estado(\"Ninguna regla salvada.\")\n",
        "        self._actualizar_botones_estado_general()\n",
        "\n",
        "\n",
        "    def _mostrar_dialogo_seleccion_salvado_via_diccionario(self) -> Dict[str, bool]: # UI, se mantiene\n",
        "        decision = {'confirmed': False, 'save_fcd': False, 'save_rfd': False}\n",
        "        dialog = tk.Toplevel(self); dialog.title(\"Seleccionar Datos a Salvar\"); dialog.geometry(\"400x200\")\n",
        "        dialog.resizable(False, False); dialog.transient(self); dialog.grab_set()\n",
        "\n",
        "        var_fcd = tk.BooleanVar(value=(self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty))\n",
        "        var_rfd = tk.BooleanVar(value=(self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC))\n",
        "\n",
        "        ttk.Label(dialog, text=\"¬øQu√© datos salvar de la b√∫squeda v√≠a Diccionario?\").pack(pady=10, padx=10)\n",
        "        chk_fcd = ttk.Checkbutton(dialog, text=\"Coincidencias del Diccionario (FCDs)\", variable=var_fcd)\n",
        "        chk_fcd.pack(anchor=tk.W, padx=20)\n",
        "        chk_fcd['state'] = 'normal' if self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty else 'disabled'\n",
        "        chk_rfd = ttk.Checkbutton(dialog, text=\"Resultados Finales de Descripciones (RFDs)\", variable=var_rfd)\n",
        "        chk_rfd.pack(anchor=tk.W, padx=20)\n",
        "        chk_rfd['state'] = 'normal' if self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC else 'disabled'\n",
        "\n",
        "        frm_btns = ttk.Frame(dialog); frm_btns.pack(pady=15)\n",
        "        def on_ok():\n",
        "            decision.update({'confirmed': True, 'save_fcd': var_fcd.get(), 'save_rfd': var_rfd.get()})\n",
        "            if not decision['save_fcd'] and not decision['save_rfd']:\n",
        "                fcd_ok = self.fcds_de_ultima_busqueda is not None and not self.fcds_de_ultima_busqueda.empty\n",
        "                rfd_ok = self.desc_finales_de_ultima_busqueda is not None and not self.desc_finales_de_ultima_busqueda.empty and self.origen_principal_resultados == OrigenResultados.VIA_DICCIONARIO_CON_RESULTADOS_DESC\n",
        "                if fcd_ok or rfd_ok: messagebox.showwarning(\"Nada Seleccionado\", \"No seleccion√≥ datos.\", parent=dialog); decision['confirmed'] = False; return\n",
        "            dialog.destroy()\n",
        "        ttk.Button(frm_btns, text=\"Confirmar\", command=on_ok).pack(side=tk.LEFT, padx=10)\n",
        "        ttk.Button(frm_btns, text=\"Cancelar\", command=dialog.destroy).pack(side=tk.LEFT, padx=10)\n",
        "\n",
        "        self.update_idletasks()\n",
        "        px, py, pw, ph = self.winfo_x(), self.winfo_y(), self.winfo_width(), self.winfo_height()\n",
        "        dw, dh = dialog.winfo_reqwidth(), dialog.winfo_reqheight()\n",
        "        dialog.geometry(f\"+{px + (pw // 2) - (dw // 2)}+{py + (ph // 2) - (dh // 2)}\")\n",
        "        self.wait_window(dialog)\n",
        "        return decision\n",
        "\n",
        "\n",
        "    def _exportar_resultados(self): # L√≥gica de exportaci√≥n se mantiene\n",
        "        if not self.reglas_guardadas: messagebox.showwarning(\"Sin Reglas\", \"No hay reglas para exportar.\"); return\n",
        "\n",
        "        ts_export = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        f_sug = f\"exportacion_reglas_{ts_export}.xlsx\"\n",
        "        ruta_save = filedialog.asksaveasfilename(title=\"Exportar Reglas...\", initialfile=f_sug, defaultextension=\".xlsx\", filetypes=[(\"Excel\", \"*.xlsx\")])\n",
        "        if not ruta_save: self._actualizar_estado(\"Exportaci√≥n cancelada.\"); return\n",
        "\n",
        "        self._actualizar_estado(\"Exportando...\"); num_r = len(self.reglas_guardadas)\n",
        "        logging.info(f\"Exportando {num_r} regla(s) a: {ruta_save}\")\n",
        "        try:\n",
        "            with pd.ExcelWriter(ruta_save, engine='openpyxl') as writer:\n",
        "                idx_export = []\n",
        "                for i, regla in enumerate(self.reglas_guardadas):\n",
        "                    tipo_short = regla.get('tipo_datos_guardados', 'DATOS').replace(\"RESULTADOS_DESCRIPCION_\", \"DESC_\").replace(\"COINCIDENCIAS_DICCIONARIO\", \"FCD\")[:10]\n",
        "                    term_short = self._sanitizar_nombre_archivo(regla.get('termino_busqueda_original','S_T'),10)\n",
        "                    id_hoja = f\"R{i+1}_{term_short}_{tipo_short}\"[:31]\n",
        "                    idx_export.append({\"ID_Regla_Hoja_Destino\": id_hoja, \"Termino_Busqueda_Original\": regla.get('termino_busqueda_original', 'N/A'),\n",
        "                                       \"Operador_Principal_OR\": regla.get('operador_principal_or', 'N/A'), \"Tipo_Datos_Guardados\": regla.get('tipo_datos_guardados', 'N/A'),\n",
        "                                       \"Fuente_Original_Resultados\": regla.get('fuente_original_guardado', 'N/A'), \"Timestamp_Guardado\": regla.get('timestamp', 'N/A'),\n",
        "                                       \"Num_Filas_Snapshot\": len(regla.get('datos_snapshot', []))})\n",
        "\n",
        "                    df_def = pd.DataFrame([{'termino_original': regla.get('termino_busqueda_original'), 'operador_principal_or': regla.get('operador_principal_or'),\n",
        "                                           'segmentos_parseados_json': json.dumps(regla.get('segmentos_parseados_para_and'), ensure_ascii=False, indent=2)}])\n",
        "                    df_def.to_excel(writer, sheet_name=f\"Def_{id_hoja}\"[:31], index=False)\n",
        "\n",
        "                    snap_list = regla.get('datos_snapshot')\n",
        "                    if snap_list:\n",
        "                        df_snap = pd.DataFrame(snap_list)\n",
        "                        if not df_snap.empty: df_snap.to_excel(writer, sheet_name=id_hoja, index=False)\n",
        "                if idx_export: pd.DataFrame(idx_export).to_excel(writer, sheet_name=\"Indice_Reglas_Exportadas\", index=False)\n",
        "            logging.info(f\"Exportaci√≥n de {num_r} regla(s) completada a {ruta_save}\")\n",
        "            messagebox.showinfo(\"√âxito\", f\"{num_r} regla(s) exportadas a:\\n{ruta_save}\")\n",
        "            self._actualizar_estado(f\"Reglas exportadas a {Path(ruta_save).name}.\")\n",
        "            if messagebox.askyesno(\"Limpiar Reglas\", \"Exportaci√≥n exitosa.\\n¬øLimpiar reglas guardadas?\"):\n",
        "                self.reglas_guardadas.clear(); self._actualizar_estado(\"Reglas limpiadas.\")\n",
        "            self._actualizar_botones_estado_general()\n",
        "        except Exception as e:\n",
        "            logging.exception(\"Error exportando reglas.\"); messagebox.showerror(\"Error Exportar\", f\"No se pudo exportar:\\n{e}\")\n",
        "            self._actualizar_estado(\"Error exportando reglas.\")\n",
        "\n",
        "\n",
        "    def _sanitizar_nombre_archivo(self, texto: str, max_len: int = 50) -> str: # Utilidad, se mantiene\n",
        "        if not texto: return \"resultados\"\n",
        "        import re # Asegurar importaci√≥n de re si se usa aqu√≠ expl√≠citamente\n",
        "        sane = re.sub(r'[^\\w\\s-]', '', texto)\n",
        "        sane = re.sub(r'[-\\s]+', '_', sane).strip('_')\n",
        "        return sane[:max_len]\n",
        "\n",
        "    def _actualizar_estado_botones_operadores(self): # UI, se mantiene la l√≥gica de habilitaci√≥n\n",
        "        if self.motor.datos_diccionario is None and self.motor.datos_descripcion is None:\n",
        "            self._deshabilitar_botones_operadores(); return\n",
        "\n",
        "        texto = self.texto_busqueda_var.get()\n",
        "        for btn in self.op_buttons.values(): btn[\"state\"] = \"normal\"\n",
        "\n",
        "        cursor_pos = self.entrada_busqueda.index(tk.INSERT)\n",
        "        antes_cursor = texto[:cursor_pos].strip()\n",
        "        ultimo_char = antes_cursor[-1] if antes_cursor else \"\"\n",
        "\n",
        "        puede_logico = bool(antes_cursor) and ultimo_char not in ['+', '|', '/', '#','<','>','=','-',' ']\n",
        "        puede_nuevo_term = not antes_cursor or ultimo_char in ['+', '|', '/',' ']\n",
        "\n",
        "        self.op_buttons[\"+\"][\"state\"] = \"normal\" if puede_logico else \"disabled\"\n",
        "        self.op_buttons[\"|\"][\"state\"] = \"normal\" if puede_logico else \"disabled\"\n",
        "        self.op_buttons[\"#\"][\"state\"] = \"normal\" if puede_nuevo_term or antes_cursor.endswith(tuple(op+\" \" for op in [\"+\", \"|\", \"/\"])) else \"disabled\"\n",
        "\n",
        "        puede_comp_rango = puede_nuevo_term or (antes_cursor and not re.search(r'[<>=\\-]$', antes_cursor))\n",
        "        for op_k in [\">\", \"<\", \">=\", \"<=\", \"-\"]: # Asumiendo mapeo interno para '‚â•', '‚â§'\n",
        "             self.op_buttons[op_k][\"state\"] = \"normal\" if puede_comp_rango else \"disabled\"\n",
        "\n",
        "    def _insertar_operador_validado(self, operador: str): # UI, se mantiene\n",
        "        if self.motor.datos_diccionario is None and self.motor.datos_descripcion is None: return\n",
        "\n",
        "        txt_insert = operador\n",
        "        if operador in [\"+\", \"|\", \"/\"]:\n",
        "            prefijo = \" \" if not self.entrada_busqueda.get()[:self.entrada_busqueda.index(tk.INSERT)].endswith(\" \") else \"\"\n",
        "            txt_insert = f\"{prefijo}{operador} \"\n",
        "        elif operador == \"#\": txt_insert = f\"{operador}\"\n",
        "\n",
        "        self.entrada_busqueda.insert(tk.INSERT, txt_insert)\n",
        "        self.entrada_busqueda.focus_set()\n",
        "\n",
        "    def _deshabilitar_botones_operadores(self): # UI, se mantiene\n",
        "        for btn in self.op_buttons.values(): btn[\"state\"] = \"disabled\"\n",
        "\n",
        "    def on_closing(self): # UI, se mantiene\n",
        "        logger.info(\"Cerrando la aplicaci√≥n...\")\n",
        "        self._guardar_configuracion()\n",
        "        self.destroy()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "9tJTTwg3c7yD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. `main.py` (Script Principal)"
      ],
      "metadata": {
        "id": "4t5RdtdPc7yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "import pandas as pd # Para la verificaci√≥n de versi√≥n y dependencia\n",
        "import openpyxl # Para la verificaci√≥n de versi√≥n y dependencia\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# Importar clases y configuraciones de los otros m√≥dulos\n",
        "from interfaz_grafica import InterfazGrafica\n",
        "from config import LOG_FILE_NAME # Usar la constante del archivo de configuraci√≥n\n",
        "\n",
        "# Configuraci√≥n del logging (similar a la original, pero centralizada aqu√≠)\n",
        "logger = logging.getLogger() # Obtener el logger ra√≠z\n",
        "logger.setLevel(logging.INFO) # Nivel por defecto, puede ser cambiado por config\n",
        "\n",
        "# Formatter\n",
        "formatter = logging.Formatter(\n",
        "    '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'\n",
        ")\n",
        "\n",
        "# File Handler\n",
        "try:\n",
        "    fh = logging.FileHandler(LOG_FILE_NAME, encoding='utf-8', mode='a')\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "except Exception as e:\n",
        "    print(f\"Error configurando FileHandler para logging: {e}\")\n",
        "    # No a√±adir handler si falla, para evitar problemas si no se puede escribir el log\n",
        "\n",
        "# Stream Handler (consola)\n",
        "sh = logging.StreamHandler()\n",
        "sh.setFormatter(formatter)\n",
        "logger.addHandler(sh)\n",
        "\n",
        "\n",
        "def verificar_dependencias():\n",
        "    \"\"\"Verifica si las dependencias cr√≠ticas est√°n instaladas.\"\"\"\n",
        "    missing_deps = []\n",
        "    try:\n",
        "        logger.info(f\"Pandas versi√≥n: {pd.__version__}\")\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"pandas\")\n",
        "        logger.critical(\"Dependencia faltante: pandas\")\n",
        "    except AttributeError: # pd puede ser importado pero __version__ no existir si es un mock o algo raro\n",
        "        missing_deps.append(\"pandas (versi√≥n desconocida)\")\n",
        "        logger.critical(\"No se pudo obtener la versi√≥n de pandas.\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        # openpyxl no siempre tiene __version__ f√°cilmente accesible a trav√©s de import openpyxl; openpyxl.__version__\n",
        "        # Es mejor solo comprobar la importaci√≥n.\n",
        "        import openpyxl as op_xl # Renombrar para evitar conflicto con la variable global en otros m√≥dulos si existiera\n",
        "        logger.info(\"openpyxl importado correctamente.\")\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"openpyxl (para archivos .xlsx)\")\n",
        "        logger.warning(\"Dependencia opcional faltante: openpyxl. Funcionalidad para .xlsx limitada.\")\n",
        "\n",
        "    if \"pandas\" in missing_deps or \"pandas (versi√≥n desconocida)\" in missing_deps:\n",
        "        error_msg_dep = (\n",
        "            f\"Faltan librer√≠as cr√≠ticas: {', '.join(d for d in missing_deps if 'pandas' in d)}.\\n\"\n",
        "            f\"Instale con: pip install pandas\\n\"\n",
        "            f\"Otras dependencias opcionales faltantes: {', '.join(d for d in missing_deps if 'openpyxl' in d)}\"\n",
        "        )\n",
        "        logger.critical(error_msg_dep)\n",
        "        try:\n",
        "            root_temp = tk.Tk()\n",
        "            root_temp.withdraw()\n",
        "            messagebox.showerror(\"Dependencias Faltantes\", error_msg_dep)\n",
        "            root_temp.destroy()\n",
        "        except tk.TclError:\n",
        "            print(f\"ERROR CR√çTICO (Tkinter no disponible): {error_msg_dep}\")\n",
        "        except Exception as e_tk_init:\n",
        "            print(f\"ERROR CR√çTICO (Error al mostrar msgbox): {e_tk_init}\\n{error_msg_dep}\")\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logger.info(\"=============================================\")\n",
        "    logger.info(f\"=== Iniciando Aplicaci√≥n Buscador ({Path(__file__).name}) ===\")\n",
        "\n",
        "    if not verificar_dependencias():\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        app = InterfazGrafica()\n",
        "        app.mainloop()\n",
        "    except Exception as main_error:\n",
        "        logger.critical(\"¬°Error fatal no capturado en la aplicaci√≥n!\", exc_info=True)\n",
        "        try:\n",
        "            root_err = tk.Tk()\n",
        "            root_err.withdraw()\n",
        "            messagebox.showerror(\"Error Fatal\", f\"Error cr√≠tico:\\n{main_error}\\nConsulte '{LOG_FILE_NAME}'.\")\n",
        "            root_err.destroy()\n",
        "        except Exception as fallback_error:\n",
        "            logger.error(f\"No se pudo mostrar el mensaje de error fatal v√≠a Tkinter: {fallback_error}\")\n",
        "            print(f\"ERROR FATAL: {main_error}. Consulte {LOG_FILE_NAME}.\")\n",
        "    finally:\n",
        "        logger.info(f\"=== Finalizando Aplicaci√≥n Buscador ({Path(__file__).name}) ===\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "HBiji2Wqc7yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C√≥mo Usar Esta Estructura:**\n",
        "\n",
        "1.  Crea una carpeta para tu proyecto.\n",
        "2.  Dentro de esa carpeta, crea los seis archivos Python (`config.py`, `enums.py`, `utilidades.py`, `motor_busqueda.py`, `interfaz_grafica.py`, `main.py`) y copia el c√≥digo correspondiente en cada uno.\n",
        "3.  Aseg√∫rate de que todas las dependencias (`pandas`, `openpyxl`) est√©n instaladas en tu entorno Python.\n",
        "4.  Ejecuta el programa desde el archivo `main.py`: `python main.py`\n",
        "\n",
        "Esta organizaci√≥n te permitir√°:\n",
        "\n",
        "* Tener cada parte del sistema con una responsabilidad clara.\n",
        "* Facilitar la modificaci√≥n y prueba de componentes individuales.\n",
        "* Mejorar la legibilidad general del proyecto.\n",
        "* Gestionar las configuraciones de forma centralizada.\n",
        "\n",
        "Espero que esta estructura te sea de gran utilidad. ¬°Av√≠same si tienes alguna otra pregunta!"
      ],
      "metadata": {
        "id": "8iuy4KATc7yF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
